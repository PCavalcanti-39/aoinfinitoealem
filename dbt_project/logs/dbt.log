[0m18:16:57.966392 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 18:16:57.972150 | e264c5ad-a0ed-4b3e-9159-5b014cfe8d43 ==============================
[0m18:16:57.972150 [info ] [MainThread]: Running with dbt=1.9.2
[0m18:16:57.973091 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/usr/app/logs', 'version_check': 'True', 'profiles_dir': '/usr/app/', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt debug --profiles-dir /usr/app/', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m18:16:57.985378 [info ] [MainThread]: dbt version: 1.9.2
[0m18:16:57.986036 [info ] [MainThread]: python version: 3.12.8
[0m18:16:57.986504 [info ] [MainThread]: python path: /opt/bitnami/python/bin/python
[0m18:16:57.986956 [info ] [MainThread]: os info: Linux-6.8.0-52-generic-x86_64-with-glibc2.36
[0m18:16:58.090045 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m18:16:58.090683 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m18:16:58.091627 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m18:16:58.515004 [info ] [MainThread]: Using profiles dir at /usr/app/
[0m18:16:58.515704 [info ] [MainThread]: Using profiles.yml file at /usr/app/profiles.yml
[0m18:16:58.516103 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project.yml
[0m18:16:58.516462 [info ] [MainThread]: adapter type: spark
[0m18:16:58.516790 [info ] [MainThread]: adapter version: 1.9.1
[0m18:16:58.523165 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `target-path` config in `dbt_project.yml` has been deprecated, and will no
longer be supported in a future version of dbt-core. If you wish to write dbt
artifacts to a custom directory, please use the --target-path CLI flag or
DBT_TARGET_PATH env var instead.
[0m18:16:58.700152 [info ] [MainThread]: Configuration:
[0m18:16:58.701090 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m18:16:58.701676 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m18:16:58.702143 [info ] [MainThread]: Required dependencies:
[0m18:16:58.702575 [debug] [MainThread]: Executing "git --help"
[0m18:16:58.704043 [info ] [MainThread]:  - git [[31mERROR[0m]

[0m18:16:58.704514 [info ] [MainThread]: Connection:
[0m18:16:58.704995 [info ] [MainThread]:   host: spark
[0m18:16:58.705353 [info ] [MainThread]:   port: 10000
[0m18:16:58.705691 [info ] [MainThread]:   cluster: None
[0m18:16:58.706069 [info ] [MainThread]:   endpoint: None
[0m18:16:58.706493 [info ] [MainThread]:   schema: default
[0m18:16:58.706881 [info ] [MainThread]:   organization: 0
[0m18:16:58.707517 [info ] [MainThread]: Registered adapter: spark=1.9.1
[0m18:16:58.848484 [debug] [MainThread]: Acquiring new spark connection 'debug'
[0m18:16:58.849190 [debug] [MainThread]: Using spark connection "debug"
[0m18:16:58.849691 [debug] [MainThread]: On debug: select 1 as id
[0m18:16:58.850220 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:16:59.937873 [debug] [MainThread]: On debug: Close
[0m18:16:59.939619 [error] [MainThread]: Encountered an error:

[0m18:16:59.944759 [error] [MainThread]: Traceback (most recent call last):
  File "/.local/lib/python3.12/site-packages/dbt/cli/requires.py", line 153, in wrapper
    result, success = func(*args, **kwargs)
                      ^^^^^^^^^^^^^^^^^^^^^
  File "/.local/lib/python3.12/site-packages/dbt/cli/requires.py", line 103, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/.local/lib/python3.12/site-packages/dbt/cli/main.py", line 414, in debug
    results = task.run()
              ^^^^^^^^^^
  File "/.local/lib/python3.12/site-packages/dbt/task/debug.py", line 144, in run
    connection_status = self.test_connection()
                        ^^^^^^^^^^^^^^^^^^^^^^
  File "/.local/lib/python3.12/site-packages/dbt/task/debug.py", line 465, in test_connection
    connection_result = self.attempt_connection(self.profile)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/.local/lib/python3.12/site-packages/dbt/task/debug.py", line 443, in attempt_connection
    adapter.debug_query()
  File "/.local/lib/python3.12/site-packages/dbt/adapters/spark/impl.py", line 517, in debug_query
    self.execute("select 1 as id")
  File "/.local/lib/python3.12/site-packages/dbt/adapters/base/impl.py", line 404, in execute
    return self.connections.execute(sql=sql, auto_begin=auto_begin, fetch=fetch, limit=limit)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/.local/lib/python3.12/site-packages/dbt/adapters/sql/connections.py", line 218, in execute
    _, cursor = self.add_query(sql, auto_begin)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/.local/lib/python3.12/site-packages/dbt/adapters/sql/connections.py", line 147, in add_query
    _execute_query_with_retry(
  File "/.local/lib/python3.12/site-packages/dbt/adapters/sql/connections.py", line 97, in _execute_query_with_retry
    cursor.execute(sql, bindings)
  File "/.local/lib/python3.12/site-packages/dbt/adapters/spark/session.py", line 227, in execute
    self._cursor.execute(sql)
  File "/.local/lib/python3.12/site-packages/dbt/adapters/spark/session.py", line 121, in execute
    spark_session = builder.getOrCreate()
                    ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/bitnami/spark/python/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/bitnami/spark/python/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/opt/bitnami/spark/python/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/bitnami/spark/python/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/opt/bitnami/spark/python/pyspark/java_gateway.py", line 104, in launch_gateway
    time.sleep(0.1)
KeyboardInterrupt

[0m18:16:59.948492 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 2.087668, "process_in_blocks": "4864", "process_kernel_time": 0.293329, "process_mem_max_rss": "110400", "process_out_blocks": "4704", "process_user_time": 2.472352}
[0m18:16:59.949850 [debug] [MainThread]: Command `dbt debug` failed at 18:16:59.949546 after 2.09 seconds
[0m18:16:59.950778 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m18:16:59.952101 [debug] [MainThread]: Flushing usage events
[0m18:33:47.705542 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 18:33:47.716987 | 01eb6a93-7874-41ac-befc-d06ba39220c3 ==============================
[0m18:33:47.716987 [info ] [MainThread]: Running with dbt=1.9.2
[0m18:33:47.718318 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --models bronze --project-dir /usr/app/ --profiles-dir /usr/app/', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m18:33:47.833123 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m18:33:47.834067 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m18:33:47.834690 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m18:33:48.047532 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `target-path` config in `dbt_project.yml` has been deprecated, and will no
longer be supported in a future version of dbt-core. If you wish to write dbt
artifacts to a custom directory, please use the --target-path CLI flag or
DBT_TARGET_PATH env var instead.
[0m18:33:48.356890 [info ] [MainThread]: Registered adapter: spark=1.9.1
[0m18:33:48.518603 [debug] [MainThread]: checksum: 12b12750b70de726cfd89136b8e24afc3f3e77597a97bff40ab7e5f9b39d5e18, vars: {}, profile: , target: , version: 1.9.2
[0m18:33:48.520164 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m18:33:51.109422 [debug] [MainThread]: Wrote artifact WritableManifest to /tmp/target/manifest.json
[0m18:33:51.117120 [debug] [MainThread]: Wrote artifact SemanticManifest to /tmp/target/semantic_manifest.json
[0m18:33:51.150193 [info ] [MainThread]: Found 10 models, 9 sources, 474 macros
[0m18:33:51.153600 [info ] [MainThread]: 
[0m18:33:51.154340 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m18:33:51.154864 [info ] [MainThread]: 
[0m18:33:51.155772 [debug] [MainThread]: Acquiring new spark connection 'master'
[0m18:33:51.166277 [debug] [ThreadPool]: Acquiring new spark connection 'list_schemas'
[0m18:33:51.188741 [debug] [ThreadPool]: Using spark connection "list_schemas"
[0m18:33:51.189747 [debug] [ThreadPool]: On list_schemas: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "default", "target_name": "dev", "connection_name": "list_schemas"} */

    show databases
  
[0m18:33:51.190434 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:34:03.010716 [debug] [ThreadPool]: SQL status: OK in 11.820 seconds
[0m18:34:03.212508 [debug] [ThreadPool]: On list_schemas: Close
[0m18:34:03.216080 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_schemas, now list_None_bronze)
[0m18:34:03.230652 [debug] [ThreadPool]: Spark adapter: NotImplemented: add_begin_query
[0m18:34:03.231303 [debug] [ThreadPool]: Using spark connection "list_None_bronze"
[0m18:34:03.231785 [debug] [ThreadPool]: On list_None_bronze: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "default", "target_name": "dev", "connection_name": "list_None_bronze"} */
show table extended in bronze like '*'
  
[0m18:34:03.232261 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m18:34:03.823542 [debug] [ThreadPool]: SQL status: OK in 0.591 seconds
[0m18:34:03.871225 [debug] [ThreadPool]: On list_None_bronze: ROLLBACK
[0m18:34:03.872142 [debug] [ThreadPool]: Spark adapter: NotImplemented: rollback
[0m18:34:03.872670 [debug] [ThreadPool]: On list_None_bronze: Close
[0m18:34:03.874453 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m18:34:03.875515 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m18:34:03.879902 [debug] [Thread-3 (]: Began running node model.liga_sudoers_dbt.auditoria_pedidos
[0m18:34:03.881977 [info ] [Thread-3 (]: 1 of 6 START sql table model bronze.auditoria_pedidos .......................... [RUN]
[0m18:34:03.883380 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_None_bronze, now model.liga_sudoers_dbt.auditoria_pedidos)
[0m18:34:03.884717 [debug] [Thread-3 (]: Began compiling node model.liga_sudoers_dbt.auditoria_pedidos
[0m18:34:03.910804 [debug] [Thread-3 (]: Writing injected SQL for node "model.liga_sudoers_dbt.auditoria_pedidos"
[0m18:34:03.915298 [debug] [Thread-3 (]: Began executing node model.liga_sudoers_dbt.auditoria_pedidos
[0m18:34:03.996323 [debug] [Thread-3 (]: Using spark connection "model.liga_sudoers_dbt.auditoria_pedidos"
[0m18:34:03.997962 [debug] [Thread-3 (]: On model.liga_sudoers_dbt.auditoria_pedidos: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "default", "target_name": "dev", "node_id": "model.liga_sudoers_dbt.auditoria_pedidos"} */
drop table if exists bronze.auditoria_pedidos
[0m18:34:03.999207 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m18:34:04.133417 [debug] [Thread-3 (]: SQL status: OK in 0.134 seconds
[0m18:34:04.263753 [debug] [Thread-3 (]: Writing runtime sql for node "model.liga_sudoers_dbt.auditoria_pedidos"
[0m18:34:04.267164 [debug] [Thread-3 (]: Spark adapter: NotImplemented: add_begin_query
[0m18:34:04.268819 [debug] [Thread-3 (]: Using spark connection "model.liga_sudoers_dbt.auditoria_pedidos"
[0m18:34:04.270192 [debug] [Thread-3 (]: On model.liga_sudoers_dbt.auditoria_pedidos: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "default", "target_name": "dev", "node_id": "model.liga_sudoers_dbt.auditoria_pedidos"} */

  
    
        create or replace table bronze.auditoria_pedidos
      
      
    using delta
      
      
      partitioned by (created_at)
      
      
    location 's3a://bronze/auditoria_pedidos'
      

      as
      
-- models/auditoria_pedidos.sql
WITH source_data AS (
    SELECT * 
    FROM oltp.auditoria_pedidos
)

SELECT 
    id_pedido,
    dispositivo,
    geohash,
    telefone,
    created_at,
    updated_at
FROM source_data

  
[0m18:34:18.964284 [debug] [Thread-3 (]: SQL status: OK in 14.693 seconds
[0m18:34:19.014859 [debug] [Thread-3 (]: On model.liga_sudoers_dbt.auditoria_pedidos: ROLLBACK
[0m18:34:19.016325 [debug] [Thread-3 (]: Spark adapter: NotImplemented: rollback
[0m18:34:19.017382 [debug] [Thread-3 (]: On model.liga_sudoers_dbt.auditoria_pedidos: Close
[0m18:34:19.023827 [info ] [Thread-3 (]: 1 of 6 OK created sql table model bronze.auditoria_pedidos ..................... [[32mOK[0m in 15.14s]
[0m18:34:19.025593 [debug] [Thread-3 (]: Finished running node model.liga_sudoers_dbt.auditoria_pedidos
[0m18:34:19.026676 [debug] [Thread-3 (]: Began running node model.liga_sudoers_dbt.categorias
[0m18:34:19.028054 [info ] [Thread-3 (]: 2 of 6 START sql incremental model bronze.categorias ........................... [RUN]
[0m18:34:19.029228 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.liga_sudoers_dbt.auditoria_pedidos, now model.liga_sudoers_dbt.categorias)
[0m18:34:19.030272 [debug] [Thread-3 (]: Began compiling node model.liga_sudoers_dbt.categorias
[0m18:34:19.041546 [debug] [Thread-3 (]: Writing injected SQL for node "model.liga_sudoers_dbt.categorias"
[0m18:34:19.043282 [debug] [Thread-3 (]: Began executing node model.liga_sudoers_dbt.categorias
[0m18:34:19.153433 [debug] [Thread-3 (]: Writing runtime sql for node "model.liga_sudoers_dbt.categorias"
[0m18:34:19.154698 [debug] [Thread-3 (]: Spark adapter: NotImplemented: add_begin_query
[0m18:34:19.155384 [debug] [Thread-3 (]: Using spark connection "model.liga_sudoers_dbt.categorias"
[0m18:34:19.156031 [debug] [Thread-3 (]: On model.liga_sudoers_dbt.categorias: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "default", "target_name": "dev", "node_id": "model.liga_sudoers_dbt.categorias"} */

  
    
        create or replace table bronze.categorias
      
      
    using delta
      
      
      
      
      
    location 's3a://bronze/categorias'
      

      as
      
-- models/categorias.sql
WITH source_data AS (
    SELECT * 
    FROM oltp.categorias
)

SELECT 
    id,
    descricao,
    created_at,
    updated_at
FROM source_data

  
[0m18:34:19.156649 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m18:34:21.400967 [debug] [Thread-3 (]: SQL status: OK in 2.244 seconds
[0m18:34:21.409258 [debug] [Thread-3 (]: On model.liga_sudoers_dbt.categorias: ROLLBACK
[0m18:34:21.410616 [debug] [Thread-3 (]: Spark adapter: NotImplemented: rollback
[0m18:34:21.411823 [debug] [Thread-3 (]: On model.liga_sudoers_dbt.categorias: Close
[0m18:34:21.413721 [info ] [Thread-3 (]: 2 of 6 OK created sql incremental model bronze.categorias ...................... [[32mOK[0m in 2.38s]
[0m18:34:21.415133 [debug] [Thread-3 (]: Finished running node model.liga_sudoers_dbt.categorias
[0m18:34:21.416064 [debug] [Thread-3 (]: Began running node model.liga_sudoers_dbt.itens_pedidos
[0m18:34:21.416967 [info ] [Thread-3 (]: 3 of 6 START sql incremental model bronze.itens_pedidos ........................ [RUN]
[0m18:34:21.417883 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.liga_sudoers_dbt.categorias, now model.liga_sudoers_dbt.itens_pedidos)
[0m18:34:21.418607 [debug] [Thread-3 (]: Began compiling node model.liga_sudoers_dbt.itens_pedidos
[0m18:34:21.426643 [debug] [Thread-3 (]: Writing injected SQL for node "model.liga_sudoers_dbt.itens_pedidos"
[0m18:34:21.429309 [debug] [Thread-3 (]: Began executing node model.liga_sudoers_dbt.itens_pedidos
[0m18:34:21.439322 [debug] [Thread-3 (]: Writing runtime sql for node "model.liga_sudoers_dbt.itens_pedidos"
[0m18:34:21.443759 [debug] [Thread-3 (]: Spark adapter: NotImplemented: add_begin_query
[0m18:34:21.445707 [debug] [Thread-3 (]: Using spark connection "model.liga_sudoers_dbt.itens_pedidos"
[0m18:34:21.448014 [debug] [Thread-3 (]: On model.liga_sudoers_dbt.itens_pedidos: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "default", "target_name": "dev", "node_id": "model.liga_sudoers_dbt.itens_pedidos"} */

  
    
        create or replace table bronze.itens_pedidos
      
      
    using delta
      
      
      partitioned by (created_at)
      
      
    location 's3a://bronze/itens_pedidos'
      

      as
      
-- models/itens_pedidos.sql
WITH source_data AS (
    SELECT * 
    FROM oltp.itens_pedidos
)

SELECT 
    id_pedido,
    id_produto,
    COALESCE(qtde, 0 ) AS qtde,
    COALESCE(valor_total, 0) AS valor_total,
    created_at,
    updated_at
FROM source_data

  
[0m18:34:21.450523 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m18:34:24.646275 [debug] [Thread-3 (]: SQL status: OK in 3.196 seconds
[0m18:34:24.653402 [debug] [Thread-3 (]: On model.liga_sudoers_dbt.itens_pedidos: ROLLBACK
[0m18:34:24.655087 [debug] [Thread-3 (]: Spark adapter: NotImplemented: rollback
[0m18:34:24.656362 [debug] [Thread-3 (]: On model.liga_sudoers_dbt.itens_pedidos: Close
[0m18:34:24.658692 [info ] [Thread-3 (]: 3 of 6 OK created sql incremental model bronze.itens_pedidos ................... [[32mOK[0m in 3.24s]
[0m18:34:24.661177 [debug] [Thread-3 (]: Finished running node model.liga_sudoers_dbt.itens_pedidos
[0m18:34:24.662266 [debug] [Thread-3 (]: Began running node model.liga_sudoers_dbt.pedidos
[0m18:34:24.663274 [info ] [Thread-3 (]: 4 of 6 START sql incremental model bronze.pedidos .............................. [RUN]
[0m18:34:24.664158 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.liga_sudoers_dbt.itens_pedidos, now model.liga_sudoers_dbt.pedidos)
[0m18:34:24.664869 [debug] [Thread-3 (]: Began compiling node model.liga_sudoers_dbt.pedidos
[0m18:34:24.672804 [debug] [Thread-3 (]: Writing injected SQL for node "model.liga_sudoers_dbt.pedidos"
[0m18:34:24.675028 [debug] [Thread-3 (]: Began executing node model.liga_sudoers_dbt.pedidos
[0m18:34:24.686072 [debug] [Thread-3 (]: Writing runtime sql for node "model.liga_sudoers_dbt.pedidos"
[0m18:34:24.688286 [debug] [Thread-3 (]: Spark adapter: NotImplemented: add_begin_query
[0m18:34:24.689202 [debug] [Thread-3 (]: Using spark connection "model.liga_sudoers_dbt.pedidos"
[0m18:34:24.690234 [debug] [Thread-3 (]: On model.liga_sudoers_dbt.pedidos: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "default", "target_name": "dev", "node_id": "model.liga_sudoers_dbt.pedidos"} */

  
    
        create or replace table bronze.pedidos
      
      
    using delta
      
      
      partitioned by (created_at)
      
      
    location 's3a://bronze/pedidos'
      

      as
      
-- models/pedidos.sql
WITH source_data AS (
    SELECT * 
    FROM oltp.pedidos
)

SELECT 
    id_pessoa,
    id,
    CAST(dt_venda as DATE) as dt_venda,
    COALESCE(valor_total, 0) AS valor_total,
    created_at,
    updated_at
FROM source_data

  
[0m18:34:24.691257 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m18:34:26.986424 [debug] [Thread-3 (]: SQL status: OK in 2.295 seconds
[0m18:34:26.990698 [debug] [Thread-3 (]: On model.liga_sudoers_dbt.pedidos: ROLLBACK
[0m18:34:26.991809 [debug] [Thread-3 (]: Spark adapter: NotImplemented: rollback
[0m18:34:26.992673 [debug] [Thread-3 (]: On model.liga_sudoers_dbt.pedidos: Close
[0m18:34:26.995081 [info ] [Thread-3 (]: 4 of 6 OK created sql incremental model bronze.pedidos ......................... [[32mOK[0m in 2.33s]
[0m18:34:26.996973 [debug] [Thread-3 (]: Finished running node model.liga_sudoers_dbt.pedidos
[0m18:34:26.998451 [debug] [Thread-3 (]: Began running node model.liga_sudoers_dbt.pessoas
[0m18:34:27.000852 [info ] [Thread-3 (]: 5 of 6 START sql incremental model bronze.pessoas .............................. [RUN]
[0m18:34:27.006339 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.liga_sudoers_dbt.pedidos, now model.liga_sudoers_dbt.pessoas)
[0m18:34:27.010256 [debug] [Thread-3 (]: Began compiling node model.liga_sudoers_dbt.pessoas
[0m18:34:27.021996 [debug] [Thread-3 (]: Writing injected SQL for node "model.liga_sudoers_dbt.pessoas"
[0m18:34:27.023514 [debug] [Thread-3 (]: Began executing node model.liga_sudoers_dbt.pessoas
[0m18:34:27.032227 [debug] [Thread-3 (]: Writing runtime sql for node "model.liga_sudoers_dbt.pessoas"
[0m18:34:27.034345 [debug] [Thread-3 (]: Spark adapter: NotImplemented: add_begin_query
[0m18:34:27.035544 [debug] [Thread-3 (]: Using spark connection "model.liga_sudoers_dbt.pessoas"
[0m18:34:27.036775 [debug] [Thread-3 (]: On model.liga_sudoers_dbt.pessoas: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "default", "target_name": "dev", "node_id": "model.liga_sudoers_dbt.pessoas"} */

  
    
        create or replace table bronze.pessoas
      
      
    using delta
      
      
      
      
      
    location 's3a://bronze/pessoas'
      

      as
      

-- models/pessoas.sql
WITH source_data AS (
    SELECT * 
    FROM oltp.pessoas
)

SELECT 
    id,
    nome,
    sexo,
    CAST(dt_nasc AS DATE) AS dt_nasc,
    created_at,
    updated_at
FROM source_data

  
[0m18:34:27.037859 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m18:34:28.663405 [debug] [Thread-3 (]: SQL status: OK in 1.625 seconds
[0m18:34:28.676420 [debug] [Thread-3 (]: On model.liga_sudoers_dbt.pessoas: ROLLBACK
[0m18:34:28.677597 [debug] [Thread-3 (]: Spark adapter: NotImplemented: rollback
[0m18:34:28.678576 [debug] [Thread-3 (]: On model.liga_sudoers_dbt.pessoas: Close
[0m18:34:28.681305 [info ] [Thread-3 (]: 5 of 6 OK created sql incremental model bronze.pessoas ......................... [[32mOK[0m in 1.68s]
[0m18:34:28.684104 [debug] [Thread-3 (]: Finished running node model.liga_sudoers_dbt.pessoas
[0m18:34:28.685993 [debug] [Thread-3 (]: Began running node model.liga_sudoers_dbt.produtos
[0m18:34:28.687590 [info ] [Thread-3 (]: 6 of 6 START sql incremental model bronze.produtos ............................. [RUN]
[0m18:34:28.689267 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.liga_sudoers_dbt.pessoas, now model.liga_sudoers_dbt.produtos)
[0m18:34:28.692260 [debug] [Thread-3 (]: Began compiling node model.liga_sudoers_dbt.produtos
[0m18:34:28.706936 [debug] [Thread-3 (]: Writing injected SQL for node "model.liga_sudoers_dbt.produtos"
[0m18:34:28.709938 [debug] [Thread-3 (]: Began executing node model.liga_sudoers_dbt.produtos
[0m18:34:28.735159 [debug] [Thread-3 (]: Writing runtime sql for node "model.liga_sudoers_dbt.produtos"
[0m18:34:28.738639 [debug] [Thread-3 (]: Spark adapter: NotImplemented: add_begin_query
[0m18:34:28.740426 [debug] [Thread-3 (]: Using spark connection "model.liga_sudoers_dbt.produtos"
[0m18:34:28.741704 [debug] [Thread-3 (]: On model.liga_sudoers_dbt.produtos: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "default", "target_name": "dev", "node_id": "model.liga_sudoers_dbt.produtos"} */

  
    
        create or replace table bronze.produtos
      
      
    using delta
      
      
      
      
      
    location 's3a://bronze/produtos'
      

      as
      
-- models/produtos.sql
WITH source_data AS (
    SELECT * 
    FROM oltp.produtos
)

SELECT 
    id_categoria,
    id,
    descricao,
    COALESCE(valor_unit, 0) AS valor_unit,
    created_at,
    updated_at
FROM source_data

  
[0m18:34:28.743059 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m18:34:30.424164 [debug] [Thread-3 (]: SQL status: OK in 1.680 seconds
[0m18:34:30.429926 [debug] [Thread-3 (]: On model.liga_sudoers_dbt.produtos: ROLLBACK
[0m18:34:30.431239 [debug] [Thread-3 (]: Spark adapter: NotImplemented: rollback
[0m18:34:30.432254 [debug] [Thread-3 (]: On model.liga_sudoers_dbt.produtos: Close
[0m18:34:30.434238 [info ] [Thread-3 (]: 6 of 6 OK created sql incremental model bronze.produtos ........................ [[32mOK[0m in 1.74s]
[0m18:34:30.436560 [debug] [Thread-3 (]: Finished running node model.liga_sudoers_dbt.produtos
[0m18:34:30.441600 [debug] [MainThread]: On master: ROLLBACK
[0m18:34:30.445606 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:34:30.446910 [debug] [MainThread]: Spark adapter: NotImplemented: rollback
[0m18:34:30.448180 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m18:34:30.449434 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m18:34:30.451541 [debug] [MainThread]: On master: ROLLBACK
[0m18:34:30.452770 [debug] [MainThread]: Spark adapter: NotImplemented: rollback
[0m18:34:30.454041 [debug] [MainThread]: On master: Close
[0m18:34:30.455511 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:34:30.456588 [debug] [MainThread]: Connection 'model.liga_sudoers_dbt.produtos' was properly closed.
[0m18:34:30.457911 [info ] [MainThread]: 
[0m18:34:30.459933 [info ] [MainThread]: Finished running 5 incremental models, 1 table model in 0 hours 0 minutes and 39.30 seconds (39.30s).
[0m18:34:30.466538 [debug] [MainThread]: Command end result
[0m18:34:30.556595 [debug] [MainThread]: Wrote artifact WritableManifest to /tmp/target/manifest.json
[0m18:34:30.562514 [debug] [MainThread]: Wrote artifact SemanticManifest to /tmp/target/semantic_manifest.json
[0m18:34:30.583140 [debug] [MainThread]: Wrote artifact RunExecutionResult to /tmp/target/run_results.json
[0m18:34:30.584427 [info ] [MainThread]: 
[0m18:34:30.585895 [info ] [MainThread]: [32mCompleted successfully[0m
[0m18:34:30.587191 [info ] [MainThread]: 
[0m18:34:30.588978 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
[0m18:34:30.592946 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 43.031094, "process_in_blocks": "6816", "process_kernel_time": 0.40496, "process_mem_max_rss": "114908", "process_out_blocks": "3288", "process_user_time": 6.180136}
[0m18:34:30.595037 [debug] [MainThread]: Command `dbt run` succeeded at 18:34:30.594407 after 43.03 seconds
[0m18:34:30.596818 [debug] [MainThread]: Flushing usage events
[0m18:34:46.370940 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 18:34:46.379507 | f0bf893c-1f27-4055-8a66-044808817c30 ==============================
[0m18:34:46.379507 [info ] [MainThread]: Running with dbt=1.9.2
[0m18:34:46.380730 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/usr/app/logs', 'version_check': 'True', 'profiles_dir': '/usr/app/', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --models silver --project-dir /usr/app/ --profiles-dir /usr/app/', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m18:34:46.509602 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m18:34:46.510286 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m18:34:46.510768 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m18:34:46.685116 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `target-path` config in `dbt_project.yml` has been deprecated, and will no
longer be supported in a future version of dbt-core. If you wish to write dbt
artifacts to a custom directory, please use the --target-path CLI flag or
DBT_TARGET_PATH env var instead.
[0m18:34:46.991034 [info ] [MainThread]: Registered adapter: spark=1.9.1
[0m18:34:47.140589 [debug] [MainThread]: checksum: 12b12750b70de726cfd89136b8e24afc3f3e77597a97bff40ab7e5f9b39d5e18, vars: {}, profile: , target: , version: 1.9.2
[0m18:34:47.282809 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m18:34:49.781325 [debug] [MainThread]: Wrote artifact WritableManifest to /tmp/target/manifest.json
[0m18:34:49.786315 [debug] [MainThread]: Wrote artifact SemanticManifest to /tmp/target/semantic_manifest.json
[0m18:34:49.808934 [info ] [MainThread]: Found 10 models, 9 sources, 474 macros
[0m18:34:49.811857 [info ] [MainThread]: 
[0m18:34:49.812610 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m18:34:49.813163 [info ] [MainThread]: 
[0m18:34:49.813968 [debug] [MainThread]: Acquiring new spark connection 'master'
[0m18:34:49.827586 [debug] [ThreadPool]: Acquiring new spark connection 'list_schemas'
[0m18:34:49.861928 [debug] [ThreadPool]: Using spark connection "list_schemas"
[0m18:34:49.862848 [debug] [ThreadPool]: On list_schemas: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "default", "target_name": "dev", "connection_name": "list_schemas"} */

    show databases
  
[0m18:34:49.863600 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:35:01.469050 [debug] [ThreadPool]: SQL status: OK in 11.605 seconds
[0m18:35:01.652135 [debug] [ThreadPool]: On list_schemas: Close
[0m18:35:01.658499 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_schemas, now list_None_silver)
[0m18:35:01.674651 [debug] [ThreadPool]: Spark adapter: NotImplemented: add_begin_query
[0m18:35:01.675582 [debug] [ThreadPool]: Using spark connection "list_None_silver"
[0m18:35:01.676338 [debug] [ThreadPool]: On list_None_silver: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "default", "target_name": "dev", "connection_name": "list_None_silver"} */
show table extended in silver like '*'
  
[0m18:35:01.677112 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m18:35:02.472174 [debug] [ThreadPool]: SQL status: OK in 0.795 seconds
[0m18:35:02.532864 [debug] [ThreadPool]: On list_None_silver: ROLLBACK
[0m18:35:02.535754 [debug] [ThreadPool]: Spark adapter: NotImplemented: rollback
[0m18:35:02.537082 [debug] [ThreadPool]: On list_None_silver: Close
[0m18:35:02.539677 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m18:35:02.540858 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m18:35:02.545916 [debug] [Thread-3 (]: Began running node model.liga_sudoers_dbt.dim_pessoas
[0m18:35:02.547863 [info ] [Thread-3 (]: 1 of 3 START sql incremental model silver.dim_pessoas .......................... [RUN]
[0m18:35:02.549494 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_None_silver, now model.liga_sudoers_dbt.dim_pessoas)
[0m18:35:02.550812 [debug] [Thread-3 (]: Began compiling node model.liga_sudoers_dbt.dim_pessoas
[0m18:35:02.579347 [debug] [Thread-3 (]: Writing injected SQL for node "model.liga_sudoers_dbt.dim_pessoas"
[0m18:35:02.581328 [debug] [Thread-3 (]: Began executing node model.liga_sudoers_dbt.dim_pessoas
[0m18:35:02.778490 [debug] [Thread-3 (]: Writing runtime sql for node "model.liga_sudoers_dbt.dim_pessoas"
[0m18:35:02.784462 [debug] [Thread-3 (]: Spark adapter: NotImplemented: add_begin_query
[0m18:35:02.786072 [debug] [Thread-3 (]: Using spark connection "model.liga_sudoers_dbt.dim_pessoas"
[0m18:35:02.787551 [debug] [Thread-3 (]: On model.liga_sudoers_dbt.dim_pessoas: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "default", "target_name": "dev", "node_id": "model.liga_sudoers_dbt.dim_pessoas"} */

  
    
        create or replace table silver.dim_pessoas
      
      
    using delta
      
      
      
      
      
    location 's3a://silver/dim_pessoas'
      

      as
      

WITH cleaned_data AS (
    SELECT 
        id,
        nome,
        CASE 
            WHEN sexo = 'M' THEN 'Masculino'
            WHEN sexo = 'F' THEN 'Feminino'
            ELSE 'Indefinido'
        END AS sexo,
        CAST(dt_nasc AS DATE) AS dt_nasc,
        created_at,
        updated_at
    FROM bronze.pessoas
    
    
)

SELECT * FROM cleaned_data;
  
[0m18:35:02.788858 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m18:35:27.079175 [debug] [Thread-3 (]: SQL status: OK in 24.290 seconds
[0m18:35:27.116304 [debug] [Thread-3 (]: On model.liga_sudoers_dbt.dim_pessoas: ROLLBACK
[0m18:35:27.116991 [debug] [Thread-3 (]: Spark adapter: NotImplemented: rollback
[0m18:35:27.117600 [debug] [Thread-3 (]: On model.liga_sudoers_dbt.dim_pessoas: Close
[0m18:35:27.121562 [info ] [Thread-3 (]: 1 of 3 OK created sql incremental model silver.dim_pessoas ..................... [[32mOK[0m in 24.57s]
[0m18:35:27.123310 [debug] [Thread-3 (]: Finished running node model.liga_sudoers_dbt.dim_pessoas
[0m18:35:27.124696 [debug] [Thread-3 (]: Began running node model.liga_sudoers_dbt.dim_produtos
[0m18:35:27.126099 [info ] [Thread-3 (]: 2 of 3 START sql incremental model silver.dim_produtos ......................... [RUN]
[0m18:35:27.127146 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.liga_sudoers_dbt.dim_pessoas, now model.liga_sudoers_dbt.dim_produtos)
[0m18:35:27.128032 [debug] [Thread-3 (]: Began compiling node model.liga_sudoers_dbt.dim_produtos
[0m18:35:27.139761 [debug] [Thread-3 (]: Writing injected SQL for node "model.liga_sudoers_dbt.dim_produtos"
[0m18:35:27.142152 [debug] [Thread-3 (]: Began executing node model.liga_sudoers_dbt.dim_produtos
[0m18:35:27.152697 [debug] [Thread-3 (]: Writing runtime sql for node "model.liga_sudoers_dbt.dim_produtos"
[0m18:35:27.154728 [debug] [Thread-3 (]: Spark adapter: NotImplemented: add_begin_query
[0m18:35:27.155968 [debug] [Thread-3 (]: Using spark connection "model.liga_sudoers_dbt.dim_produtos"
[0m18:35:27.157218 [debug] [Thread-3 (]: On model.liga_sudoers_dbt.dim_produtos: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "default", "target_name": "dev", "node_id": "model.liga_sudoers_dbt.dim_produtos"} */

  
    
        create or replace table silver.dim_produtos
      
      
    using delta
      
      
      
      
      
    location 's3a://silver/dim_produtos'
      

      as
      

WITH cleaned_data AS (
    SELECT 
        p.id, 
        c.descricao AS cat_desc, 
        p.descricao, 
        p.created_at, 
        p.updated_at     
    FROM bronze.produtos p 
            INNER JOIN bronze.categorias c ON c.id = p.id_categoria
    
)

SELECT * FROM cleaned_data;
  
[0m18:35:27.158380 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m18:35:39.949698 [debug] [Thread-3 (]: SQL status: OK in 12.791 seconds
[0m18:35:39.958973 [debug] [Thread-3 (]: On model.liga_sudoers_dbt.dim_produtos: ROLLBACK
[0m18:35:39.960055 [debug] [Thread-3 (]: Spark adapter: NotImplemented: rollback
[0m18:35:39.961550 [debug] [Thread-3 (]: On model.liga_sudoers_dbt.dim_produtos: Close
[0m18:35:39.963671 [info ] [Thread-3 (]: 2 of 3 OK created sql incremental model silver.dim_produtos .................... [[32mOK[0m in 12.84s]
[0m18:35:39.966070 [debug] [Thread-3 (]: Finished running node model.liga_sudoers_dbt.dim_produtos
[0m18:35:39.967349 [debug] [Thread-3 (]: Began running node model.liga_sudoers_dbt.fato_pedidos
[0m18:35:39.968807 [info ] [Thread-3 (]: 3 of 3 START sql incremental model silver.fato_pedidos ......................... [RUN]
[0m18:35:39.970360 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.liga_sudoers_dbt.dim_produtos, now model.liga_sudoers_dbt.fato_pedidos)
[0m18:35:39.971491 [debug] [Thread-3 (]: Began compiling node model.liga_sudoers_dbt.fato_pedidos
[0m18:35:39.986232 [debug] [Thread-3 (]: Writing injected SQL for node "model.liga_sudoers_dbt.fato_pedidos"
[0m18:35:39.989178 [debug] [Thread-3 (]: Began executing node model.liga_sudoers_dbt.fato_pedidos
[0m18:35:39.999912 [debug] [Thread-3 (]: Writing runtime sql for node "model.liga_sudoers_dbt.fato_pedidos"
[0m18:35:40.003026 [debug] [Thread-3 (]: Spark adapter: NotImplemented: add_begin_query
[0m18:35:40.004287 [debug] [Thread-3 (]: Using spark connection "model.liga_sudoers_dbt.fato_pedidos"
[0m18:35:40.005442 [debug] [Thread-3 (]: On model.liga_sudoers_dbt.fato_pedidos: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "default", "target_name": "dev", "node_id": "model.liga_sudoers_dbt.fato_pedidos"} */

  
    
        create or replace table silver.fato_pedidos
      
      
    using delta
      
      
      partitioned by (dt_venda)
      
      
    location 's3a://silver/fato_pedidos'
      

      as
      
WITH orders AS (
    SELECT 
        p.id AS id_pedido, 
        p.id_pessoa, 
        i.id_produto, 
        a.dispositivo, 
        a.geohash,
        a.telefone,
        p.dt_venda,
        i.qtde, 
        i.valor_total AS valor_unit,
        p.valor_total, 
        p.created_at,
        p.updated_at
    FROM bronze.pedidos p 
        INNER JOIN bronze.itens_pedidos i 
        ON p.id = i.id_pedido 
        INNER JOIN bronze.auditoria_pedidos a 
        ON p.id = a.id_pedido
    

)

SELECT * FROM orders;
  
[0m18:35:40.006550 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m18:36:04.767544 [debug] [Thread-3 (]: SQL status: OK in 24.761 seconds
[0m18:36:04.771452 [debug] [Thread-3 (]: On model.liga_sudoers_dbt.fato_pedidos: ROLLBACK
[0m18:36:04.772266 [debug] [Thread-3 (]: Spark adapter: NotImplemented: rollback
[0m18:36:04.773127 [debug] [Thread-3 (]: On model.liga_sudoers_dbt.fato_pedidos: Close
[0m18:36:04.775782 [info ] [Thread-3 (]: 3 of 3 OK created sql incremental model silver.fato_pedidos .................... [[32mOK[0m in 24.80s]
[0m18:36:04.777758 [debug] [Thread-3 (]: Finished running node model.liga_sudoers_dbt.fato_pedidos
[0m18:36:04.781462 [debug] [MainThread]: On master: ROLLBACK
[0m18:36:04.782384 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:36:04.783363 [debug] [MainThread]: Spark adapter: NotImplemented: rollback
[0m18:36:04.784245 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m18:36:04.785046 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m18:36:04.785826 [debug] [MainThread]: On master: ROLLBACK
[0m18:36:04.786572 [debug] [MainThread]: Spark adapter: NotImplemented: rollback
[0m18:36:04.787222 [debug] [MainThread]: On master: Close
[0m18:36:04.788295 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:36:04.789085 [debug] [MainThread]: Connection 'model.liga_sudoers_dbt.fato_pedidos' was properly closed.
[0m18:36:04.790028 [info ] [MainThread]: 
[0m18:36:04.790840 [info ] [MainThread]: Finished running 3 incremental models in 0 hours 1 minutes and 14.98 seconds (74.98s).
[0m18:36:04.793338 [debug] [MainThread]: Command end result
[0m18:36:04.867730 [debug] [MainThread]: Wrote artifact WritableManifest to /tmp/target/manifest.json
[0m18:36:04.872900 [debug] [MainThread]: Wrote artifact SemanticManifest to /tmp/target/semantic_manifest.json
[0m18:36:04.893473 [debug] [MainThread]: Wrote artifact RunExecutionResult to /tmp/target/run_results.json
[0m18:36:04.894350 [info ] [MainThread]: 
[0m18:36:04.895368 [info ] [MainThread]: [32mCompleted successfully[0m
[0m18:36:04.896474 [info ] [MainThread]: 
[0m18:36:04.897698 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
[0m18:36:04.902042 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 78.67447, "process_in_blocks": "0", "process_kernel_time": 0.42201, "process_mem_max_rss": "115640", "process_out_blocks": "3232", "process_user_time": 6.155154}
[0m18:36:04.903358 [debug] [MainThread]: Command `dbt run` succeeded at 18:36:04.903093 after 78.68 seconds
[0m18:36:04.904255 [debug] [MainThread]: Flushing usage events
[0m18:36:11.604919 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 18:36:11.613079 | 7697c46f-3a46-4785-9e11-2a7c680850f5 ==============================
[0m18:36:11.613079 [info ] [MainThread]: Running with dbt=1.9.2
[0m18:36:11.614312 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/usr/app/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt run --models gold --project-dir /usr/app/ --profiles-dir /usr/app/', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m18:36:11.739600 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m18:36:11.740253 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m18:36:11.740719 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m18:36:11.911341 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `target-path` config in `dbt_project.yml` has been deprecated, and will no
longer be supported in a future version of dbt-core. If you wish to write dbt
artifacts to a custom directory, please use the --target-path CLI flag or
DBT_TARGET_PATH env var instead.
[0m18:36:12.265758 [info ] [MainThread]: Registered adapter: spark=1.9.1
[0m18:36:12.469224 [debug] [MainThread]: checksum: 12b12750b70de726cfd89136b8e24afc3f3e77597a97bff40ab7e5f9b39d5e18, vars: {}, profile: , target: , version: 1.9.2
[0m18:36:12.665076 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m18:36:15.515524 [debug] [MainThread]: Wrote artifact WritableManifest to /tmp/target/manifest.json
[0m18:36:15.520127 [debug] [MainThread]: Wrote artifact SemanticManifest to /tmp/target/semantic_manifest.json
[0m18:36:15.539414 [info ] [MainThread]: Found 10 models, 9 sources, 474 macros
[0m18:36:15.541904 [info ] [MainThread]: 
[0m18:36:15.542611 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m18:36:15.543109 [info ] [MainThread]: 
[0m18:36:15.543895 [debug] [MainThread]: Acquiring new spark connection 'master'
[0m18:36:15.545173 [debug] [ThreadPool]: Acquiring new spark connection 'list_schemas'
[0m18:36:15.566462 [debug] [ThreadPool]: Using spark connection "list_schemas"
[0m18:36:15.567125 [debug] [ThreadPool]: On list_schemas: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "default", "target_name": "dev", "connection_name": "list_schemas"} */

    show databases
  
[0m18:36:15.567739 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:36:27.602523 [debug] [ThreadPool]: SQL status: OK in 12.034 seconds
[0m18:36:27.781167 [debug] [ThreadPool]: On list_schemas: Close
[0m18:36:27.803183 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_schemas, now list_None_gold)
[0m18:36:27.813971 [debug] [ThreadPool]: Spark adapter: NotImplemented: add_begin_query
[0m18:36:27.814589 [debug] [ThreadPool]: Using spark connection "list_None_gold"
[0m18:36:27.815081 [debug] [ThreadPool]: On list_None_gold: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "default", "target_name": "dev", "connection_name": "list_None_gold"} */
show table extended in gold like '*'
  
[0m18:36:27.815814 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m18:36:28.448506 [debug] [ThreadPool]: SQL status: OK in 0.633 seconds
[0m18:36:28.479108 [debug] [ThreadPool]: On list_None_gold: ROLLBACK
[0m18:36:28.480121 [debug] [ThreadPool]: Spark adapter: NotImplemented: rollback
[0m18:36:28.480918 [debug] [ThreadPool]: On list_None_gold: Close
[0m18:36:28.482741 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m18:36:28.483711 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m18:36:28.491747 [debug] [Thread-3 (]: Began running node model.liga_sudoers_dbt.itens_by_person
[0m18:36:28.493627 [info ] [Thread-3 (]: 1 of 1 START sql incremental model gold.itens_by_person ........................ [RUN]
[0m18:36:28.495431 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_None_gold, now model.liga_sudoers_dbt.itens_by_person)
[0m18:36:28.504746 [debug] [Thread-3 (]: Began compiling node model.liga_sudoers_dbt.itens_by_person
[0m18:36:28.556243 [debug] [Thread-3 (]: Writing injected SQL for node "model.liga_sudoers_dbt.itens_by_person"
[0m18:36:28.558197 [debug] [Thread-3 (]: Began executing node model.liga_sudoers_dbt.itens_by_person
[0m18:36:28.799201 [debug] [Thread-3 (]: Writing runtime sql for node "model.liga_sudoers_dbt.itens_by_person"
[0m18:36:28.800892 [debug] [Thread-3 (]: Spark adapter: NotImplemented: add_begin_query
[0m18:36:28.801712 [debug] [Thread-3 (]: Using spark connection "model.liga_sudoers_dbt.itens_by_person"
[0m18:36:28.802679 [debug] [Thread-3 (]: On model.liga_sudoers_dbt.itens_by_person: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "default", "target_name": "dev", "node_id": "model.liga_sudoers_dbt.itens_by_person"} */

  
    
        create or replace table gold.itens_by_person
      
      
    using delta
      
      
      partitioned by (dt_venda)
      
      
    location 's3a://gold/itens_by_person'
      

      as
      
WITH itens_person AS (
    SELECT 
        dp.nome, 
        dp.sexo, 
        dp.dt_nasc, 
        dpr.cat_desc, 
        dpr.descricao, 
        fp.id_pedido, 
        fp.dt_venda, 
        fp.dispositivo, 
        fp.geohash, 
        COALESCE(valor_unit, 0 ) as total
    FROM silver.fato_pedidos fp
        INNER JOIN silver.dim_produtos dpr ON dpr.id = fp.id_produto
        INNER JOIN silver.dim_pessoas dp ON dp.id = fp.id_pessoa    
    

    ORDER BY 6 desc, 1, 2, 3, 4, 5, 7, 8
)

SELECT * FROM itens_person;
  
[0m18:36:28.803634 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m18:37:31.111585 [debug] [Thread-3 (]: SQL status: OK in 62.308 seconds
[0m18:37:31.154641 [debug] [Thread-3 (]: On model.liga_sudoers_dbt.itens_by_person: ROLLBACK
[0m18:37:31.155398 [debug] [Thread-3 (]: Spark adapter: NotImplemented: rollback
[0m18:37:31.155967 [debug] [Thread-3 (]: On model.liga_sudoers_dbt.itens_by_person: Close
[0m18:37:31.160637 [info ] [Thread-3 (]: 1 of 1 OK created sql incremental model gold.itens_by_person ................... [[32mOK[0m in 62.66s]
[0m18:37:31.162002 [debug] [Thread-3 (]: Finished running node model.liga_sudoers_dbt.itens_by_person
[0m18:37:31.165002 [debug] [MainThread]: On master: ROLLBACK
[0m18:37:31.165780 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:37:31.166661 [debug] [MainThread]: Spark adapter: NotImplemented: rollback
[0m18:37:31.167752 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m18:37:31.169612 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m18:37:31.172481 [debug] [MainThread]: On master: ROLLBACK
[0m18:37:31.175129 [debug] [MainThread]: Spark adapter: NotImplemented: rollback
[0m18:37:31.176749 [debug] [MainThread]: On master: Close
[0m18:37:31.178593 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:37:31.179488 [debug] [MainThread]: Connection 'model.liga_sudoers_dbt.itens_by_person' was properly closed.
[0m18:37:31.180397 [info ] [MainThread]: 
[0m18:37:31.181366 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 1 minutes and 15.64 seconds (75.64s).
[0m18:37:31.183832 [debug] [MainThread]: Command end result
[0m18:37:31.237060 [debug] [MainThread]: Wrote artifact WritableManifest to /tmp/target/manifest.json
[0m18:37:31.244377 [debug] [MainThread]: Wrote artifact SemanticManifest to /tmp/target/semantic_manifest.json
[0m18:37:31.263114 [debug] [MainThread]: Wrote artifact RunExecutionResult to /tmp/target/run_results.json
[0m18:37:31.264113 [info ] [MainThread]: 
[0m18:37:31.265276 [info ] [MainThread]: [32mCompleted successfully[0m
[0m18:37:31.266219 [info ] [MainThread]: 
[0m18:37:31.267264 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m18:37:31.270638 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 79.82614, "process_in_blocks": "0", "process_kernel_time": 0.493706, "process_mem_max_rss": "115184", "process_out_blocks": "3152", "process_user_time": 6.920886}
[0m18:37:31.272264 [debug] [MainThread]: Command `dbt run` succeeded at 18:37:31.271867 after 79.83 seconds
[0m18:37:31.273383 [debug] [MainThread]: Flushing usage events
[0m18:38:14.143114 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 18:38:14.153272 | 2f364926-9c2b-41f0-9a29-9f6261f6fbf9 ==============================
[0m18:38:14.153272 [info ] [MainThread]: Running with dbt=1.9.2
[0m18:38:14.154576 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/usr/app/logs', 'profiles_dir': '/usr/app/', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt docs generate --project-dir /usr/app/ --profiles-dir /usr/app/', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m18:38:14.342233 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m18:38:14.342906 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m18:38:14.343506 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m18:38:14.607737 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `target-path` config in `dbt_project.yml` has been deprecated, and will no
longer be supported in a future version of dbt-core. If you wish to write dbt
artifacts to a custom directory, please use the --target-path CLI flag or
DBT_TARGET_PATH env var instead.
[0m18:38:14.978062 [info ] [MainThread]: Registered adapter: spark=1.9.1
[0m18:38:15.166883 [debug] [MainThread]: checksum: 12b12750b70de726cfd89136b8e24afc3f3e77597a97bff40ab7e5f9b39d5e18, vars: {}, profile: , target: , version: 1.9.2
[0m18:38:15.341036 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m18:38:18.143383 [info ] [MainThread]: Found 10 models, 9 sources, 474 macros
[0m18:38:18.147008 [info ] [MainThread]: 
[0m18:38:18.147687 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m18:38:18.148215 [info ] [MainThread]: 
[0m18:38:18.149005 [debug] [MainThread]: Acquiring new spark connection 'master'
[0m18:38:18.165722 [debug] [ThreadPool]: Acquiring new spark connection 'list_None_default'
[0m18:38:18.199028 [debug] [ThreadPool]: Spark adapter: NotImplemented: add_begin_query
[0m18:38:18.199975 [debug] [ThreadPool]: Using spark connection "list_None_default"
[0m18:38:18.200806 [debug] [ThreadPool]: On list_None_default: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "default", "target_name": "dev", "connection_name": "list_None_default"} */
show table extended in default like '*'
  
[0m18:38:18.201630 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:38:30.895666 [debug] [ThreadPool]: SQL status: OK in 12.693 seconds
[0m18:38:31.157820 [debug] [ThreadPool]: On list_None_default: ROLLBACK
[0m18:38:31.159028 [debug] [ThreadPool]: Spark adapter: NotImplemented: rollback
[0m18:38:31.159808 [debug] [ThreadPool]: On list_None_default: Close
[0m18:38:31.167079 [debug] [Thread-3 (]: Began running node model.liga_sudoers_dbt.auditoria_pedidos
[0m18:38:31.168658 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_None_default, now model.liga_sudoers_dbt.auditoria_pedidos)
[0m18:38:31.169828 [debug] [Thread-3 (]: Began compiling node model.liga_sudoers_dbt.auditoria_pedidos
[0m18:38:31.194058 [debug] [Thread-3 (]: Writing injected SQL for node "model.liga_sudoers_dbt.auditoria_pedidos"
[0m18:38:31.195277 [debug] [Thread-3 (]: Began executing node model.liga_sudoers_dbt.auditoria_pedidos
[0m18:38:31.199499 [debug] [Thread-3 (]: Finished running node model.liga_sudoers_dbt.auditoria_pedidos
[0m18:38:31.200294 [debug] [Thread-3 (]: Began running node model.liga_sudoers_dbt.categorias
[0m18:38:31.201098 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.liga_sudoers_dbt.auditoria_pedidos, now model.liga_sudoers_dbt.categorias)
[0m18:38:31.201706 [debug] [Thread-3 (]: Began compiling node model.liga_sudoers_dbt.categorias
[0m18:38:31.207113 [debug] [Thread-3 (]: Writing injected SQL for node "model.liga_sudoers_dbt.categorias"
[0m18:38:31.208294 [debug] [Thread-3 (]: Began executing node model.liga_sudoers_dbt.categorias
[0m18:38:31.209594 [debug] [Thread-3 (]: Finished running node model.liga_sudoers_dbt.categorias
[0m18:38:31.210263 [debug] [Thread-3 (]: Began running node model.liga_sudoers_dbt.dim_pessoas
[0m18:38:31.211458 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.liga_sudoers_dbt.categorias, now model.liga_sudoers_dbt.dim_pessoas)
[0m18:38:31.212211 [debug] [Thread-3 (]: Began compiling node model.liga_sudoers_dbt.dim_pessoas
[0m18:38:31.218169 [debug] [Thread-3 (]: Writing injected SQL for node "model.liga_sudoers_dbt.dim_pessoas"
[0m18:38:31.219527 [debug] [Thread-3 (]: Began executing node model.liga_sudoers_dbt.dim_pessoas
[0m18:38:31.221505 [debug] [Thread-3 (]: Finished running node model.liga_sudoers_dbt.dim_pessoas
[0m18:38:31.222352 [debug] [Thread-3 (]: Began running node model.liga_sudoers_dbt.dim_produtos
[0m18:38:31.223246 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.liga_sudoers_dbt.dim_pessoas, now model.liga_sudoers_dbt.dim_produtos)
[0m18:38:31.223910 [debug] [Thread-3 (]: Began compiling node model.liga_sudoers_dbt.dim_produtos
[0m18:38:31.236899 [debug] [Thread-3 (]: Writing injected SQL for node "model.liga_sudoers_dbt.dim_produtos"
[0m18:38:31.238467 [debug] [Thread-3 (]: Began executing node model.liga_sudoers_dbt.dim_produtos
[0m18:38:31.242004 [debug] [Thread-3 (]: Finished running node model.liga_sudoers_dbt.dim_produtos
[0m18:38:31.243790 [debug] [Thread-3 (]: Began running node model.liga_sudoers_dbt.fato_pedidos
[0m18:38:31.245572 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.liga_sudoers_dbt.dim_produtos, now model.liga_sudoers_dbt.fato_pedidos)
[0m18:38:31.246938 [debug] [Thread-3 (]: Began compiling node model.liga_sudoers_dbt.fato_pedidos
[0m18:38:31.260901 [debug] [Thread-3 (]: Writing injected SQL for node "model.liga_sudoers_dbt.fato_pedidos"
[0m18:38:31.262591 [debug] [Thread-3 (]: Began executing node model.liga_sudoers_dbt.fato_pedidos
[0m18:38:31.264532 [debug] [Thread-3 (]: Finished running node model.liga_sudoers_dbt.fato_pedidos
[0m18:38:31.265609 [debug] [Thread-3 (]: Began running node model.liga_sudoers_dbt.itens_by_person
[0m18:38:31.266877 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.liga_sudoers_dbt.fato_pedidos, now model.liga_sudoers_dbt.itens_by_person)
[0m18:38:31.267941 [debug] [Thread-3 (]: Began compiling node model.liga_sudoers_dbt.itens_by_person
[0m18:38:31.282594 [debug] [Thread-3 (]: Writing injected SQL for node "model.liga_sudoers_dbt.itens_by_person"
[0m18:38:31.284386 [debug] [Thread-3 (]: Began executing node model.liga_sudoers_dbt.itens_by_person
[0m18:38:31.286408 [debug] [Thread-3 (]: Finished running node model.liga_sudoers_dbt.itens_by_person
[0m18:38:31.287497 [debug] [Thread-3 (]: Began running node model.liga_sudoers_dbt.itens_pedidos
[0m18:38:31.288649 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.liga_sudoers_dbt.itens_by_person, now model.liga_sudoers_dbt.itens_pedidos)
[0m18:38:31.289591 [debug] [Thread-3 (]: Began compiling node model.liga_sudoers_dbt.itens_pedidos
[0m18:38:31.296124 [debug] [Thread-3 (]: Writing injected SQL for node "model.liga_sudoers_dbt.itens_pedidos"
[0m18:38:31.297397 [debug] [Thread-3 (]: Began executing node model.liga_sudoers_dbt.itens_pedidos
[0m18:38:31.298772 [debug] [Thread-3 (]: Finished running node model.liga_sudoers_dbt.itens_pedidos
[0m18:38:31.299435 [debug] [Thread-3 (]: Began running node model.liga_sudoers_dbt.pedidos
[0m18:38:31.300146 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.liga_sudoers_dbt.itens_pedidos, now model.liga_sudoers_dbt.pedidos)
[0m18:38:31.300697 [debug] [Thread-3 (]: Began compiling node model.liga_sudoers_dbt.pedidos
[0m18:38:31.308328 [debug] [Thread-3 (]: Writing injected SQL for node "model.liga_sudoers_dbt.pedidos"
[0m18:38:31.310258 [debug] [Thread-3 (]: Began executing node model.liga_sudoers_dbt.pedidos
[0m18:38:31.312092 [debug] [Thread-3 (]: Finished running node model.liga_sudoers_dbt.pedidos
[0m18:38:31.313291 [debug] [Thread-3 (]: Began running node model.liga_sudoers_dbt.pessoas
[0m18:38:31.314305 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.liga_sudoers_dbt.pedidos, now model.liga_sudoers_dbt.pessoas)
[0m18:38:31.315262 [debug] [Thread-3 (]: Began compiling node model.liga_sudoers_dbt.pessoas
[0m18:38:31.321160 [debug] [Thread-3 (]: Writing injected SQL for node "model.liga_sudoers_dbt.pessoas"
[0m18:38:31.322261 [debug] [Thread-3 (]: Began executing node model.liga_sudoers_dbt.pessoas
[0m18:38:31.323433 [debug] [Thread-3 (]: Finished running node model.liga_sudoers_dbt.pessoas
[0m18:38:31.324058 [debug] [Thread-3 (]: Began running node model.liga_sudoers_dbt.produtos
[0m18:38:31.324658 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.liga_sudoers_dbt.pessoas, now model.liga_sudoers_dbt.produtos)
[0m18:38:31.325218 [debug] [Thread-3 (]: Began compiling node model.liga_sudoers_dbt.produtos
[0m18:38:31.331581 [debug] [Thread-3 (]: Writing injected SQL for node "model.liga_sudoers_dbt.produtos"
[0m18:38:31.333122 [debug] [Thread-3 (]: Began executing node model.liga_sudoers_dbt.produtos
[0m18:38:31.334495 [debug] [Thread-3 (]: Finished running node model.liga_sudoers_dbt.produtos
[0m18:38:31.336698 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:38:31.337739 [debug] [MainThread]: Connection 'model.liga_sudoers_dbt.produtos' was properly closed.
[0m18:38:31.343234 [debug] [MainThread]: Command end result
[0m18:38:31.482524 [debug] [MainThread]: Wrote artifact WritableManifest to /tmp/target/manifest.json
[0m18:38:31.488888 [debug] [MainThread]: Wrote artifact SemanticManifest to /tmp/target/semantic_manifest.json
[0m18:38:31.509567 [debug] [MainThread]: Wrote artifact RunExecutionResult to /tmp/target/run_results.json
[0m18:38:31.514658 [debug] [MainThread]: Acquiring new spark connection 'generate_catalog'
[0m18:38:31.515461 [info ] [MainThread]: Building catalog
[0m18:38:31.541479 [debug] [ThreadPool]: Acquiring new spark connection 'silver'
[0m18:38:31.542362 [debug] [ThreadPool]: On "silver": cache miss for schema ".silver", this is inefficient
[0m18:38:31.548129 [debug] [ThreadPool]: Spark adapter: NotImplemented: add_begin_query
[0m18:38:31.549227 [debug] [ThreadPool]: Using spark connection "silver"
[0m18:38:31.549983 [debug] [ThreadPool]: On silver: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "default", "target_name": "dev", "connection_name": "silver"} */
show table extended in silver like '*'
  
[0m18:38:31.550675 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:38:32.435484 [debug] [ThreadPool]: SQL status: OK in 0.885 seconds
[0m18:38:33.071975 [debug] [ThreadPool]: While listing relations in database=, schema=silver, found: dim_pessoas, dim_produtos, fato_pedidos
[0m18:38:33.073143 [debug] [ThreadPool]: Spark adapter: Getting table schema for relation silver.dim_pessoas
[0m18:38:33.074075 [debug] [ThreadPool]: Spark adapter: Getting table schema for relation silver.dim_produtos
[0m18:38:33.074913 [debug] [ThreadPool]: Spark adapter: Getting table schema for relation silver.fato_pedidos
[0m18:38:33.075754 [debug] [ThreadPool]: On silver: ROLLBACK
[0m18:38:33.076536 [debug] [ThreadPool]: Spark adapter: NotImplemented: rollback
[0m18:38:33.077226 [debug] [ThreadPool]: On silver: Close
[0m18:38:33.078403 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly silver, now bronze)
[0m18:38:33.079225 [debug] [ThreadPool]: On "bronze": cache miss for schema ".bronze", this is inefficient
[0m18:38:33.084963 [debug] [ThreadPool]: Spark adapter: NotImplemented: add_begin_query
[0m18:38:33.086024 [debug] [ThreadPool]: Using spark connection "bronze"
[0m18:38:33.086795 [debug] [ThreadPool]: On bronze: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "default", "target_name": "dev", "connection_name": "bronze"} */
show table extended in bronze like '*'
  
[0m18:38:33.087530 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m18:38:33.431896 [debug] [ThreadPool]: SQL status: OK in 0.344 seconds
[0m18:38:33.470130 [debug] [ThreadPool]: While listing relations in database=, schema=bronze, found: auditoria_pedidos, categorias, itens_pedidos, pedidos, pessoas, produtos
[0m18:38:33.470939 [debug] [ThreadPool]: Spark adapter: Getting table schema for relation bronze.auditoria_pedidos
[0m18:38:33.471731 [debug] [ThreadPool]: Spark adapter: Getting table schema for relation bronze.categorias
[0m18:38:33.472492 [debug] [ThreadPool]: Spark adapter: Getting table schema for relation bronze.itens_pedidos
[0m18:38:33.473227 [debug] [ThreadPool]: Spark adapter: Getting table schema for relation bronze.pedidos
[0m18:38:33.473954 [debug] [ThreadPool]: Spark adapter: Getting table schema for relation bronze.pessoas
[0m18:38:33.474695 [debug] [ThreadPool]: Spark adapter: Getting table schema for relation bronze.produtos
[0m18:38:33.475468 [debug] [ThreadPool]: On bronze: ROLLBACK
[0m18:38:33.476152 [debug] [ThreadPool]: Spark adapter: NotImplemented: rollback
[0m18:38:33.476786 [debug] [ThreadPool]: On bronze: Close
[0m18:38:33.477827 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly bronze, now default)
[0m18:38:33.484400 [debug] [MainThread]: Wrote artifact CatalogArtifact to /tmp/target/catalog.json
[0m18:38:33.534408 [debug] [MainThread]: Wrote artifact WritableManifest to /tmp/target/manifest.json
[0m18:38:33.538118 [debug] [MainThread]: Wrote artifact SemanticManifest to /tmp/target/semantic_manifest.json
[0m18:38:33.538686 [info ] [MainThread]: Catalog written to /tmp/target/catalog.json
[0m18:38:33.540799 [debug] [MainThread]: Resource report: {"command_name": "generate", "command_success": true, "command_wall_clock_time": 19.708405, "process_in_blocks": "2096", "process_kernel_time": 0.548687, "process_mem_max_rss": "113892", "process_out_blocks": "6608", "process_user_time": 7.47711}
[0m18:38:33.541723 [debug] [MainThread]: Command `dbt docs generate` succeeded at 18:38:33.541513 after 19.71 seconds
[0m18:38:33.542318 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m18:38:33.542768 [debug] [MainThread]: Connection 'default' was properly closed.
[0m18:38:33.543282 [debug] [MainThread]: Flushing usage events
[0m18:38:41.438964 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 18:38:41.445980 | e38ff257-07ff-443a-83ea-c9aecfce00d7 ==============================
[0m18:38:41.445980 [info ] [MainThread]: Running with dbt=1.9.2
[0m18:38:41.447345 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt docs serve --project-dir /usr/app/ --profiles-dir /usr/app/ --port 8085 --host 0.0.0.0', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m18:38:41.571287 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m18:38:41.572067 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m18:38:41.572802 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m18:38:41.808832 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `target-path` config in `dbt_project.yml` has been deprecated, and will no
longer be supported in a future version of dbt-core. If you wish to write dbt
artifacts to a custom directory, please use the --target-path CLI flag or
DBT_TARGET_PATH env var instead.
[0m18:41:58.069012 [error] [MainThread]: Encountered an error:

[0m18:41:58.073616 [error] [MainThread]: Traceback (most recent call last):
  File "/.local/lib/python3.12/site-packages/dbt/cli/requires.py", line 153, in wrapper
    result, success = func(*args, **kwargs)
                      ^^^^^^^^^^^^^^^^^^^^^
  File "/.local/lib/python3.12/site-packages/dbt/cli/requires.py", line 103, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/.local/lib/python3.12/site-packages/dbt/cli/requires.py", line 235, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/.local/lib/python3.12/site-packages/dbt/cli/requires.py", line 264, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/.local/lib/python3.12/site-packages/dbt/cli/requires.py", line 311, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/.local/lib/python3.12/site-packages/dbt/cli/main.py", line 301, in docs_serve
    results = task.run()
              ^^^^^^^^^^
  File "/.local/lib/python3.12/site-packages/dbt/task/docs/serve.py", line 29, in run
    httpd.serve_forever()
  File "/opt/bitnami/python/lib/python3.12/socketserver.py", line 235, in serve_forever
    ready = selector.select(poll_interval)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/bitnami/python/lib/python3.12/selectors.py", line 415, in select
    fd_event_list = self._selector.poll(timeout)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt

[0m18:41:58.074792 [debug] [MainThread]: Resource report: {"command_name": "serve", "command_success": false, "command_wall_clock_time": 196.81088, "process_in_blocks": "288", "process_kernel_time": 0.413758, "process_mem_max_rss": "102472", "process_out_blocks": "3352", "process_user_time": 3.726831}
[0m18:41:58.075315 [debug] [MainThread]: Command `dbt docs serve` failed at 18:41:58.075197 after 196.81 seconds
[0m18:41:58.076156 [debug] [MainThread]: Flushing usage events
[0m18:53:22.023060 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 18:53:22.045904 | b63b1a04-ee24-4510-b7dc-c3375936062b ==============================
[0m18:53:22.045904 [info ] [MainThread]: Running with dbt=1.9.2
[0m18:53:22.047502 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/', 'version_check': 'True', 'debug': 'False', 'log_path': '/usr/app/logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt run --models bronze --project-dir /usr/app/ --profiles-dir /usr/app/', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m18:53:22.149815 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m18:53:22.150781 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m18:53:22.151538 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m18:53:22.364622 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `target-path` config in `dbt_project.yml` has been deprecated, and will no
longer be supported in a future version of dbt-core. If you wish to write dbt
artifacts to a custom directory, please use the --target-path CLI flag or
DBT_TARGET_PATH env var instead.
[0m18:53:22.817853 [info ] [MainThread]: Registered adapter: spark=1.9.1
[0m18:53:23.029780 [debug] [MainThread]: checksum: 12b12750b70de726cfd89136b8e24afc3f3e77597a97bff40ab7e5f9b39d5e18, vars: {}, profile: , target: , version: 1.9.2
[0m18:53:23.233053 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m18:53:26.963696 [debug] [MainThread]: Wrote artifact WritableManifest to /tmp/target/manifest.json
[0m18:53:26.969467 [debug] [MainThread]: Wrote artifact SemanticManifest to /tmp/target/semantic_manifest.json
[0m18:53:26.999435 [info ] [MainThread]: Found 10 models, 9 sources, 474 macros
[0m18:53:27.003151 [info ] [MainThread]: 
[0m18:53:27.003860 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m18:53:27.004437 [info ] [MainThread]: 
[0m18:53:27.005287 [debug] [MainThread]: Acquiring new spark connection 'master'
[0m18:53:27.017350 [debug] [ThreadPool]: Acquiring new spark connection 'list_schemas'
[0m18:53:27.038984 [debug] [ThreadPool]: Using spark connection "list_schemas"
[0m18:53:27.039981 [debug] [ThreadPool]: On list_schemas: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "default", "target_name": "dev", "connection_name": "list_schemas"} */

    show databases
  
[0m18:53:27.040945 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:53:44.907348 [debug] [ThreadPool]: SQL status: OK in 17.866 seconds
[0m18:53:45.136076 [debug] [ThreadPool]: On list_schemas: Close
[0m18:53:45.142471 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_schemas, now list_None_bronze)
[0m18:53:45.158937 [debug] [ThreadPool]: Spark adapter: NotImplemented: add_begin_query
[0m18:53:45.159837 [debug] [ThreadPool]: Using spark connection "list_None_bronze"
[0m18:53:45.160642 [debug] [ThreadPool]: On list_None_bronze: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "default", "target_name": "dev", "connection_name": "list_None_bronze"} */
show table extended in bronze like '*'
  
[0m18:53:45.161495 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m18:53:46.694785 [debug] [ThreadPool]: SQL status: OK in 1.533 seconds
[0m18:53:46.764463 [debug] [ThreadPool]: On list_None_bronze: ROLLBACK
[0m18:53:46.765262 [debug] [ThreadPool]: Spark adapter: NotImplemented: rollback
[0m18:53:46.765797 [debug] [ThreadPool]: On list_None_bronze: Close
[0m18:53:46.769680 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m18:53:46.770553 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m18:53:46.774280 [debug] [Thread-3 (]: Began running node model.liga_sudoers_dbt.auditoria_pedidos
[0m18:53:46.776010 [info ] [Thread-3 (]: 1 of 6 START sql table model bronze.auditoria_pedidos .......................... [RUN]
[0m18:53:46.777376 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_None_bronze, now model.liga_sudoers_dbt.auditoria_pedidos)
[0m18:53:46.778424 [debug] [Thread-3 (]: Began compiling node model.liga_sudoers_dbt.auditoria_pedidos
[0m18:53:46.806895 [debug] [Thread-3 (]: Writing injected SQL for node "model.liga_sudoers_dbt.auditoria_pedidos"
[0m18:53:46.810718 [debug] [Thread-3 (]: Began executing node model.liga_sudoers_dbt.auditoria_pedidos
[0m18:53:46.963112 [debug] [Thread-3 (]: Writing runtime sql for node "model.liga_sudoers_dbt.auditoria_pedidos"
[0m18:53:46.965010 [debug] [Thread-3 (]: Spark adapter: NotImplemented: add_begin_query
[0m18:53:46.965768 [debug] [Thread-3 (]: Using spark connection "model.liga_sudoers_dbt.auditoria_pedidos"
[0m18:53:46.966427 [debug] [Thread-3 (]: On model.liga_sudoers_dbt.auditoria_pedidos: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "default", "target_name": "dev", "node_id": "model.liga_sudoers_dbt.auditoria_pedidos"} */

  
    
        create or replace table bronze.auditoria_pedidos
      
      
    using delta
      
      
      partitioned by (created_at)
      
      
    location 's3a://bronze/auditoria_pedidos'
      

      as
      
-- models/auditoria_pedidos.sql
WITH source_data AS (
    SELECT * 
    FROM oltp.auditoria_pedidos
)

SELECT 
    id_pedido,
    dispositivo,
    geohash,
    telefone,
    created_at,
    updated_at
FROM source_data

  
[0m18:53:46.967066 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m18:54:20.347751 [debug] [Thread-3 (]: SQL status: OK in 33.380 seconds
[0m18:54:20.442257 [debug] [Thread-3 (]: On model.liga_sudoers_dbt.auditoria_pedidos: ROLLBACK
[0m18:54:20.443986 [debug] [Thread-3 (]: Spark adapter: NotImplemented: rollback
[0m18:54:20.445335 [debug] [Thread-3 (]: On model.liga_sudoers_dbt.auditoria_pedidos: Close
[0m18:54:20.452367 [info ] [Thread-3 (]: 1 of 6 OK created sql table model bronze.auditoria_pedidos ..................... [[32mOK[0m in 33.67s]
[0m18:54:20.455055 [debug] [Thread-3 (]: Finished running node model.liga_sudoers_dbt.auditoria_pedidos
[0m18:54:20.456628 [debug] [Thread-3 (]: Began running node model.liga_sudoers_dbt.categorias
[0m18:54:20.458826 [info ] [Thread-3 (]: 2 of 6 START sql incremental model bronze.categorias ........................... [RUN]
[0m18:54:20.460813 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.liga_sudoers_dbt.auditoria_pedidos, now model.liga_sudoers_dbt.categorias)
[0m18:54:20.461953 [debug] [Thread-3 (]: Began compiling node model.liga_sudoers_dbt.categorias
[0m18:54:20.483877 [debug] [Thread-3 (]: Writing injected SQL for node "model.liga_sudoers_dbt.categorias"
[0m18:54:20.493042 [debug] [Thread-3 (]: Began executing node model.liga_sudoers_dbt.categorias
[0m18:54:20.631774 [debug] [Thread-3 (]: Spark adapter: NotImplemented: add_begin_query
[0m18:54:20.633704 [debug] [Thread-3 (]: Using spark connection "model.liga_sudoers_dbt.categorias"
[0m18:54:20.635494 [debug] [Thread-3 (]: On model.liga_sudoers_dbt.categorias: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "default", "target_name": "dev", "node_id": "model.liga_sudoers_dbt.categorias"} */

  
    create or replace temporary view categorias__dbt_tmp as
      
-- models/categorias.sql
WITH source_data AS (
    SELECT * 
    FROM oltp.categorias
)

SELECT 
    id,
    descricao,
    created_at,
    updated_at
FROM source_data

    -- Pega apenas registros que foram atualizados após o último update da tabela
    WHERE updated_at > (SELECT MAX(updated_at) FROM bronze.categorias)

  
[0m18:54:20.637278 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m18:54:21.546475 [debug] [Thread-3 (]: SQL status: OK in 0.909 seconds
[0m18:54:21.644444 [debug] [Thread-3 (]: Using spark connection "model.liga_sudoers_dbt.categorias"
[0m18:54:21.646197 [debug] [Thread-3 (]: On model.liga_sudoers_dbt.categorias: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "default", "target_name": "dev", "node_id": "model.liga_sudoers_dbt.categorias"} */

      describe extended bronze.categorias
  
[0m18:54:21.988788 [debug] [Thread-3 (]: SQL status: OK in 0.341 seconds
[0m18:54:22.096390 [debug] [Thread-3 (]: Writing runtime sql for node "model.liga_sudoers_dbt.categorias"
[0m18:54:22.098556 [debug] [Thread-3 (]: Using spark connection "model.liga_sudoers_dbt.categorias"
[0m18:54:22.099802 [debug] [Thread-3 (]: On model.liga_sudoers_dbt.categorias: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "default", "target_name": "dev", "node_id": "model.liga_sudoers_dbt.categorias"} */

    -- back compat for old kwarg name
  
  
  
      
          
          
      
  

  

  merge into bronze.categorias as DBT_INTERNAL_DEST
      using categorias__dbt_tmp as DBT_INTERNAL_SOURCE
      on 
              DBT_INTERNAL_SOURCE.id = DBT_INTERNAL_DEST.id
          

      when matched then update set
         * 

      when not matched then insert *

[0m18:54:35.706935 [debug] [Thread-3 (]: SQL status: OK in 13.606 seconds
[0m18:54:35.721166 [debug] [Thread-3 (]: On model.liga_sudoers_dbt.categorias: ROLLBACK
[0m18:54:35.723496 [debug] [Thread-3 (]: Spark adapter: NotImplemented: rollback
[0m18:54:35.724812 [debug] [Thread-3 (]: On model.liga_sudoers_dbt.categorias: Close
[0m18:54:35.727160 [info ] [Thread-3 (]: 2 of 6 OK created sql incremental model bronze.categorias ...................... [[32mOK[0m in 15.27s]
[0m18:54:35.729631 [debug] [Thread-3 (]: Finished running node model.liga_sudoers_dbt.categorias
[0m18:54:35.731206 [debug] [Thread-3 (]: Began running node model.liga_sudoers_dbt.itens_pedidos
[0m18:54:35.733000 [info ] [Thread-3 (]: 3 of 6 START sql incremental model bronze.itens_pedidos ........................ [RUN]
[0m18:54:35.734471 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.liga_sudoers_dbt.categorias, now model.liga_sudoers_dbt.itens_pedidos)
[0m18:54:35.735678 [debug] [Thread-3 (]: Began compiling node model.liga_sudoers_dbt.itens_pedidos
[0m18:54:35.749164 [debug] [Thread-3 (]: Writing injected SQL for node "model.liga_sudoers_dbt.itens_pedidos"
[0m18:54:35.752486 [debug] [Thread-3 (]: Began executing node model.liga_sudoers_dbt.itens_pedidos
[0m18:54:35.768956 [debug] [Thread-3 (]: Spark adapter: NotImplemented: add_begin_query
[0m18:54:35.771596 [debug] [Thread-3 (]: Using spark connection "model.liga_sudoers_dbt.itens_pedidos"
[0m18:54:35.773329 [debug] [Thread-3 (]: On model.liga_sudoers_dbt.itens_pedidos: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "default", "target_name": "dev", "node_id": "model.liga_sudoers_dbt.itens_pedidos"} */

  
    create or replace temporary view itens_pedidos__dbt_tmp as
      
-- models/itens_pedidos.sql
WITH source_data AS (
    SELECT * 
    FROM oltp.itens_pedidos
)

SELECT 
    id_pedido,
    id_produto,
    COALESCE(qtde, 0 ) AS qtde,
    COALESCE(valor_total, 0) AS valor_total,
    created_at,
    updated_at
FROM source_data

    -- Pega apenas registros que foram atualizados após o último update da tabela
    WHERE updated_at > (SELECT MAX(updated_at) FROM bronze.itens_pedidos)

  
[0m18:54:35.774577 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m18:54:36.231167 [debug] [Thread-3 (]: SQL status: OK in 0.456 seconds
[0m18:54:36.241365 [debug] [Thread-3 (]: Using spark connection "model.liga_sudoers_dbt.itens_pedidos"
[0m18:54:36.243648 [debug] [Thread-3 (]: On model.liga_sudoers_dbt.itens_pedidos: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "default", "target_name": "dev", "node_id": "model.liga_sudoers_dbt.itens_pedidos"} */

      describe extended bronze.itens_pedidos
  
[0m18:54:36.369050 [debug] [Thread-3 (]: SQL status: OK in 0.124 seconds
[0m18:54:36.399952 [debug] [Thread-3 (]: Writing runtime sql for node "model.liga_sudoers_dbt.itens_pedidos"
[0m18:54:36.402084 [debug] [Thread-3 (]: Using spark connection "model.liga_sudoers_dbt.itens_pedidos"
[0m18:54:36.403534 [debug] [Thread-3 (]: On model.liga_sudoers_dbt.itens_pedidos: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "default", "target_name": "dev", "node_id": "model.liga_sudoers_dbt.itens_pedidos"} */

    -- back compat for old kwarg name
  
  
  
      
          
          
      
  

  

  merge into bronze.itens_pedidos as DBT_INTERNAL_DEST
      using itens_pedidos__dbt_tmp as DBT_INTERNAL_SOURCE
      on 
              DBT_INTERNAL_SOURCE.id_pedido = DBT_INTERNAL_DEST.id_pedido
          

      when matched then update set
         * 

      when not matched then insert *

[0m18:54:45.905071 [debug] [Thread-3 (]: SQL status: OK in 9.500 seconds
[0m18:54:45.930788 [debug] [Thread-3 (]: On model.liga_sudoers_dbt.itens_pedidos: ROLLBACK
[0m18:54:45.933458 [debug] [Thread-3 (]: Spark adapter: NotImplemented: rollback
[0m18:54:45.935070 [debug] [Thread-3 (]: On model.liga_sudoers_dbt.itens_pedidos: Close
[0m18:54:45.937753 [info ] [Thread-3 (]: 3 of 6 OK created sql incremental model bronze.itens_pedidos ................... [[32mOK[0m in 10.20s]
[0m18:54:45.940101 [debug] [Thread-3 (]: Finished running node model.liga_sudoers_dbt.itens_pedidos
[0m18:54:45.941912 [debug] [Thread-3 (]: Began running node model.liga_sudoers_dbt.pedidos
[0m18:54:45.944294 [info ] [Thread-3 (]: 4 of 6 START sql incremental model bronze.pedidos .............................. [RUN]
[0m18:54:45.946280 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.liga_sudoers_dbt.itens_pedidos, now model.liga_sudoers_dbt.pedidos)
[0m18:54:45.947900 [debug] [Thread-3 (]: Began compiling node model.liga_sudoers_dbt.pedidos
[0m18:54:45.961724 [debug] [Thread-3 (]: Writing injected SQL for node "model.liga_sudoers_dbt.pedidos"
[0m18:54:45.963991 [debug] [Thread-3 (]: Began executing node model.liga_sudoers_dbt.pedidos
[0m18:54:45.978960 [debug] [Thread-3 (]: Spark adapter: NotImplemented: add_begin_query
[0m18:54:45.980691 [debug] [Thread-3 (]: Using spark connection "model.liga_sudoers_dbt.pedidos"
[0m18:54:45.983381 [debug] [Thread-3 (]: On model.liga_sudoers_dbt.pedidos: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "default", "target_name": "dev", "node_id": "model.liga_sudoers_dbt.pedidos"} */

  
    create or replace temporary view pedidos__dbt_tmp as
      
-- models/pedidos.sql
WITH source_data AS (
    SELECT * 
    FROM oltp.pedidos
)

SELECT 
    id_pessoa,
    id,
    CAST(dt_venda as DATE) as dt_venda,
    COALESCE(valor_total, 0) AS valor_total,
    created_at,
    updated_at
FROM source_data

    -- Pega apenas registros que foram atualizados após o último update da tabela
    WHERE updated_at > (SELECT MAX(updated_at) FROM bronze.pedidos)

  
[0m18:54:45.984837 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m18:54:46.578848 [debug] [Thread-3 (]: SQL status: OK in 0.594 seconds
[0m18:54:46.590664 [debug] [Thread-3 (]: Using spark connection "model.liga_sudoers_dbt.pedidos"
[0m18:54:46.593201 [debug] [Thread-3 (]: On model.liga_sudoers_dbt.pedidos: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "default", "target_name": "dev", "node_id": "model.liga_sudoers_dbt.pedidos"} */

      describe extended bronze.pedidos
  
[0m18:54:46.743588 [debug] [Thread-3 (]: SQL status: OK in 0.148 seconds
[0m18:54:46.780523 [debug] [Thread-3 (]: Writing runtime sql for node "model.liga_sudoers_dbt.pedidos"
[0m18:54:46.789720 [debug] [Thread-3 (]: Using spark connection "model.liga_sudoers_dbt.pedidos"
[0m18:54:46.791370 [debug] [Thread-3 (]: On model.liga_sudoers_dbt.pedidos: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "default", "target_name": "dev", "node_id": "model.liga_sudoers_dbt.pedidos"} */

    -- back compat for old kwarg name
  
  
  
      
          
          
      
  

  

  merge into bronze.pedidos as DBT_INTERNAL_DEST
      using pedidos__dbt_tmp as DBT_INTERNAL_SOURCE
      on 
              DBT_INTERNAL_SOURCE.id = DBT_INTERNAL_DEST.id
          

      when matched then update set
         * 

      when not matched then insert *

[0m18:54:57.114313 [debug] [Thread-3 (]: SQL status: OK in 10.321 seconds
[0m18:54:57.124442 [debug] [Thread-3 (]: On model.liga_sudoers_dbt.pedidos: ROLLBACK
[0m18:54:57.130964 [debug] [Thread-3 (]: Spark adapter: NotImplemented: rollback
[0m18:54:57.132278 [debug] [Thread-3 (]: On model.liga_sudoers_dbt.pedidos: Close
[0m18:54:57.139325 [info ] [Thread-3 (]: 4 of 6 OK created sql incremental model bronze.pedidos ......................... [[32mOK[0m in 11.19s]
[0m18:54:57.142448 [debug] [Thread-3 (]: Finished running node model.liga_sudoers_dbt.pedidos
[0m18:54:57.145688 [debug] [Thread-3 (]: Began running node model.liga_sudoers_dbt.pessoas
[0m18:54:57.147821 [info ] [Thread-3 (]: 5 of 6 START sql incremental model bronze.pessoas .............................. [RUN]
[0m18:54:57.151220 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.liga_sudoers_dbt.pedidos, now model.liga_sudoers_dbt.pessoas)
[0m18:54:57.153595 [debug] [Thread-3 (]: Began compiling node model.liga_sudoers_dbt.pessoas
[0m18:54:57.178609 [debug] [Thread-3 (]: Writing injected SQL for node "model.liga_sudoers_dbt.pessoas"
[0m18:54:57.183975 [debug] [Thread-3 (]: Began executing node model.liga_sudoers_dbt.pessoas
[0m18:54:57.201068 [debug] [Thread-3 (]: Spark adapter: NotImplemented: add_begin_query
[0m18:54:57.204769 [debug] [Thread-3 (]: Using spark connection "model.liga_sudoers_dbt.pessoas"
[0m18:54:57.208068 [debug] [Thread-3 (]: On model.liga_sudoers_dbt.pessoas: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "default", "target_name": "dev", "node_id": "model.liga_sudoers_dbt.pessoas"} */

  
    create or replace temporary view pessoas__dbt_tmp as
      

-- models/pessoas.sql
WITH source_data AS (
    SELECT * 
    FROM oltp.pessoas
)

SELECT 
    id,
    nome,
    sexo,
    CAST(dt_nasc AS DATE) AS dt_nasc,
    created_at,
    updated_at
FROM source_data

    -- Pega apenas registros que foram atualizados após o último update da tabela
    WHERE updated_at > (SELECT MAX(updated_at) FROM bronze.pessoas)

  
[0m18:54:57.212116 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m18:54:57.920659 [debug] [Thread-3 (]: SQL status: OK in 0.709 seconds
[0m18:54:57.942577 [debug] [Thread-3 (]: Using spark connection "model.liga_sudoers_dbt.pessoas"
[0m18:54:57.947069 [debug] [Thread-3 (]: On model.liga_sudoers_dbt.pessoas: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "default", "target_name": "dev", "node_id": "model.liga_sudoers_dbt.pessoas"} */

      describe extended bronze.pessoas
  
[0m18:54:58.219892 [debug] [Thread-3 (]: SQL status: OK in 0.270 seconds
[0m18:54:58.267288 [debug] [Thread-3 (]: Writing runtime sql for node "model.liga_sudoers_dbt.pessoas"
[0m18:54:58.270201 [debug] [Thread-3 (]: Using spark connection "model.liga_sudoers_dbt.pessoas"
[0m18:54:58.272155 [debug] [Thread-3 (]: On model.liga_sudoers_dbt.pessoas: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "default", "target_name": "dev", "node_id": "model.liga_sudoers_dbt.pessoas"} */

    -- back compat for old kwarg name
  
  
  
      
          
          
      
  

  

  merge into bronze.pessoas as DBT_INTERNAL_DEST
      using pessoas__dbt_tmp as DBT_INTERNAL_SOURCE
      on 
              DBT_INTERNAL_SOURCE.id = DBT_INTERNAL_DEST.id
          

      when matched then update set
         * 

      when not matched then insert *

[0m18:55:13.479539 [debug] [Thread-3 (]: SQL status: OK in 15.204 seconds
[0m18:55:13.498486 [debug] [Thread-3 (]: On model.liga_sudoers_dbt.pessoas: ROLLBACK
[0m18:55:13.506916 [debug] [Thread-3 (]: Spark adapter: NotImplemented: rollback
[0m18:55:13.524352 [debug] [Thread-3 (]: On model.liga_sudoers_dbt.pessoas: Close
[0m18:55:13.553297 [info ] [Thread-3 (]: 5 of 6 OK created sql incremental model bronze.pessoas ......................... [[32mOK[0m in 16.40s]
[0m18:55:13.572104 [debug] [Thread-3 (]: Finished running node model.liga_sudoers_dbt.pessoas
[0m18:55:13.576695 [debug] [Thread-3 (]: Began running node model.liga_sudoers_dbt.produtos
[0m18:55:13.587012 [info ] [Thread-3 (]: 6 of 6 START sql incremental model bronze.produtos ............................. [RUN]
[0m18:55:13.595859 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.liga_sudoers_dbt.pessoas, now model.liga_sudoers_dbt.produtos)
[0m18:55:13.600140 [debug] [Thread-3 (]: Began compiling node model.liga_sudoers_dbt.produtos
[0m18:55:13.640420 [debug] [Thread-3 (]: Writing injected SQL for node "model.liga_sudoers_dbt.produtos"
[0m18:55:13.643347 [debug] [Thread-3 (]: Began executing node model.liga_sudoers_dbt.produtos
[0m18:55:13.665098 [debug] [Thread-3 (]: Spark adapter: NotImplemented: add_begin_query
[0m18:55:13.667837 [debug] [Thread-3 (]: Using spark connection "model.liga_sudoers_dbt.produtos"
[0m18:55:13.670606 [debug] [Thread-3 (]: On model.liga_sudoers_dbt.produtos: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "default", "target_name": "dev", "node_id": "model.liga_sudoers_dbt.produtos"} */

  
    create or replace temporary view produtos__dbt_tmp as
      
-- models/produtos.sql
WITH source_data AS (
    SELECT * 
    FROM oltp.produtos
)

SELECT 
    id_categoria,
    id,
    descricao,
    COALESCE(valor_unit, 0) AS valor_unit,
    created_at,
    updated_at
FROM source_data

    -- Pega apenas registros que foram atualizados após o último update da tabela
    WHERE updated_at > (SELECT MAX(updated_at) FROM bronze.produtos)

  
[0m18:55:13.673376 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m18:55:14.738799 [debug] [Thread-3 (]: SQL status: OK in 1.065 seconds
[0m18:55:14.773098 [debug] [Thread-3 (]: Using spark connection "model.liga_sudoers_dbt.produtos"
[0m18:55:14.781325 [debug] [Thread-3 (]: On model.liga_sudoers_dbt.produtos: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "default", "target_name": "dev", "node_id": "model.liga_sudoers_dbt.produtos"} */

      describe extended bronze.produtos
  
[0m18:55:14.956282 [debug] [Thread-3 (]: SQL status: OK in 0.173 seconds
[0m18:55:15.012454 [debug] [Thread-3 (]: Writing runtime sql for node "model.liga_sudoers_dbt.produtos"
[0m18:55:15.017624 [debug] [Thread-3 (]: Using spark connection "model.liga_sudoers_dbt.produtos"
[0m18:55:15.020945 [debug] [Thread-3 (]: On model.liga_sudoers_dbt.produtos: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "default", "target_name": "dev", "node_id": "model.liga_sudoers_dbt.produtos"} */

    -- back compat for old kwarg name
  
  
  
      
          
          
      
  

  

  merge into bronze.produtos as DBT_INTERNAL_DEST
      using produtos__dbt_tmp as DBT_INTERNAL_SOURCE
      on 
              DBT_INTERNAL_SOURCE.id = DBT_INTERNAL_DEST.id
          

      when matched then update set
         * 

      when not matched then insert *

[0m18:55:31.494355 [debug] [Thread-3 (]: SQL status: OK in 16.471 seconds
[0m18:55:31.505060 [debug] [Thread-3 (]: On model.liga_sudoers_dbt.produtos: ROLLBACK
[0m18:55:31.507462 [debug] [Thread-3 (]: Spark adapter: NotImplemented: rollback
[0m18:55:31.511756 [debug] [Thread-3 (]: On model.liga_sudoers_dbt.produtos: Close
[0m18:55:31.517650 [info ] [Thread-3 (]: 6 of 6 OK created sql incremental model bronze.produtos ........................ [[32mOK[0m in 17.92s]
[0m18:55:31.525516 [debug] [Thread-3 (]: Finished running node model.liga_sudoers_dbt.produtos
[0m18:55:31.549153 [debug] [MainThread]: On master: ROLLBACK
[0m18:55:31.550700 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:55:31.553682 [debug] [MainThread]: Spark adapter: NotImplemented: rollback
[0m18:55:31.559478 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m18:55:31.562597 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m18:55:31.564011 [debug] [MainThread]: On master: ROLLBACK
[0m18:55:31.565300 [debug] [MainThread]: Spark adapter: NotImplemented: rollback
[0m18:55:31.566670 [debug] [MainThread]: On master: Close
[0m18:55:31.571557 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:55:31.576176 [debug] [MainThread]: Connection 'model.liga_sudoers_dbt.produtos' was properly closed.
[0m18:55:31.578701 [info ] [MainThread]: 
[0m18:55:31.582264 [info ] [MainThread]: Finished running 5 incremental models, 1 table model in 0 hours 2 minutes and 4.57 seconds (124.57s).
[0m18:55:31.595570 [debug] [MainThread]: Command end result
[0m18:55:31.759697 [debug] [MainThread]: Wrote artifact WritableManifest to /tmp/target/manifest.json
[0m18:55:31.773325 [debug] [MainThread]: Wrote artifact SemanticManifest to /tmp/target/semantic_manifest.json
[0m18:55:31.817475 [debug] [MainThread]: Wrote artifact RunExecutionResult to /tmp/target/run_results.json
[0m18:55:31.820756 [info ] [MainThread]: 
[0m18:55:31.824760 [info ] [MainThread]: [32mCompleted successfully[0m
[0m18:55:31.829604 [info ] [MainThread]: 
[0m18:55:31.832122 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
[0m18:55:31.842358 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 130.01476, "process_in_blocks": "552", "process_kernel_time": 0.780984, "process_mem_max_rss": "116388", "process_out_blocks": "3344", "process_user_time": 10.205734}
[0m18:55:31.845186 [debug] [MainThread]: Command `dbt run` succeeded at 18:55:31.844330 after 130.02 seconds
[0m18:55:31.847986 [debug] [MainThread]: Flushing usage events
[0m18:55:52.277599 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 18:55:52.306059 | 4ef1e620-4f45-4e67-905f-c29230299641 ==============================
[0m18:55:52.306059 [info ] [MainThread]: Running with dbt=1.9.2
[0m18:55:52.308221 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --models silver --project-dir /usr/app/ --profiles-dir /usr/app/', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m18:55:52.594962 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m18:55:52.598064 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m18:55:52.602964 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m18:55:53.199688 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `target-path` config in `dbt_project.yml` has been deprecated, and will no
longer be supported in a future version of dbt-core. If you wish to write dbt
artifacts to a custom directory, please use the --target-path CLI flag or
DBT_TARGET_PATH env var instead.
[0m18:55:53.911337 [info ] [MainThread]: Registered adapter: spark=1.9.1
[0m18:55:54.247868 [debug] [MainThread]: checksum: 12b12750b70de726cfd89136b8e24afc3f3e77597a97bff40ab7e5f9b39d5e18, vars: {}, profile: , target: , version: 1.9.2
[0m18:55:54.739665 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m18:56:01.965940 [debug] [MainThread]: Wrote artifact WritableManifest to /tmp/target/manifest.json
[0m18:56:01.980416 [debug] [MainThread]: Wrote artifact SemanticManifest to /tmp/target/semantic_manifest.json
[0m18:56:02.075710 [info ] [MainThread]: Found 10 models, 9 sources, 474 macros
[0m18:56:02.084129 [info ] [MainThread]: 
[0m18:56:02.086913 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m18:56:02.089000 [info ] [MainThread]: 
[0m18:56:02.091726 [debug] [MainThread]: Acquiring new spark connection 'master'
[0m18:56:02.121448 [debug] [ThreadPool]: Acquiring new spark connection 'list_schemas'
[0m18:56:02.169085 [debug] [ThreadPool]: Using spark connection "list_schemas"
[0m18:56:02.170283 [debug] [ThreadPool]: On list_schemas: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "default", "target_name": "dev", "connection_name": "list_schemas"} */

    show databases
  
[0m18:56:02.172609 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:56:41.143438 [debug] [ThreadPool]: SQL status: OK in 38.971 seconds
[0m18:56:41.551160 [debug] [ThreadPool]: On list_schemas: Close
[0m18:56:41.565806 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_schemas, now list_None_silver)
[0m18:56:41.606465 [debug] [ThreadPool]: Spark adapter: NotImplemented: add_begin_query
[0m18:56:41.609925 [debug] [ThreadPool]: Using spark connection "list_None_silver"
[0m18:56:41.612501 [debug] [ThreadPool]: On list_None_silver: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "default", "target_name": "dev", "connection_name": "list_None_silver"} */
show table extended in silver like '*'
  
[0m18:56:41.614838 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m18:56:46.030325 [debug] [ThreadPool]: SQL status: OK in 4.416 seconds
[0m18:56:46.238063 [debug] [ThreadPool]: On list_None_silver: ROLLBACK
[0m18:56:46.240137 [debug] [ThreadPool]: Spark adapter: NotImplemented: rollback
[0m18:56:46.241772 [debug] [ThreadPool]: On list_None_silver: Close
[0m18:56:46.250661 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m18:56:46.252984 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m18:56:46.261145 [debug] [Thread-3 (]: Began running node model.liga_sudoers_dbt.dim_pessoas
[0m18:56:46.265182 [info ] [Thread-3 (]: 1 of 3 START sql incremental model silver.dim_pessoas .......................... [RUN]
[0m18:56:46.268616 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_None_silver, now model.liga_sudoers_dbt.dim_pessoas)
[0m18:56:46.272320 [debug] [Thread-3 (]: Began compiling node model.liga_sudoers_dbt.dim_pessoas
[0m18:56:46.356261 [debug] [Thread-3 (]: Writing injected SQL for node "model.liga_sudoers_dbt.dim_pessoas"
[0m18:56:46.359497 [debug] [Thread-3 (]: Began executing node model.liga_sudoers_dbt.dim_pessoas
[0m18:56:46.646523 [debug] [Thread-3 (]: Spark adapter: NotImplemented: add_begin_query
[0m18:56:46.647840 [debug] [Thread-3 (]: Using spark connection "model.liga_sudoers_dbt.dim_pessoas"
[0m18:56:46.649207 [debug] [Thread-3 (]: On model.liga_sudoers_dbt.dim_pessoas: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "default", "target_name": "dev", "node_id": "model.liga_sudoers_dbt.dim_pessoas"} */

  
    create or replace temporary view dim_pessoas__dbt_tmp as
      

WITH cleaned_data AS (
    SELECT 
        id,
        nome,
        CASE 
            WHEN sexo = 'M' THEN 'Masculino'
            WHEN sexo = 'F' THEN 'Feminino'
            ELSE 'Indefinido'
        END AS sexo,
        CAST(dt_nasc AS DATE) AS dt_nasc,
        created_at,
        updated_at
    FROM bronze.pessoas
    
        -- Pega apenas registros que foram atualizados após o último update da tabela
        WHERE updated_at > (SELECT MAX(updated_at) FROM silver.dim_pessoas)
    
    
)

SELECT * FROM cleaned_data;
  
[0m18:56:46.650571 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m18:57:12.099126 [debug] [Thread-3 (]: SQL status: OK in 25.448 seconds
[0m18:57:12.210059 [debug] [Thread-3 (]: Using spark connection "model.liga_sudoers_dbt.dim_pessoas"
[0m18:57:12.212490 [debug] [Thread-3 (]: On model.liga_sudoers_dbt.dim_pessoas: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "default", "target_name": "dev", "node_id": "model.liga_sudoers_dbt.dim_pessoas"} */

      describe extended silver.dim_pessoas
  
[0m18:57:12.994712 [debug] [Thread-3 (]: SQL status: OK in 0.779 seconds
[0m18:57:13.184443 [debug] [Thread-3 (]: Writing runtime sql for node "model.liga_sudoers_dbt.dim_pessoas"
[0m18:57:13.189674 [debug] [Thread-3 (]: Using spark connection "model.liga_sudoers_dbt.dim_pessoas"
[0m18:57:13.192122 [debug] [Thread-3 (]: On model.liga_sudoers_dbt.dim_pessoas: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "default", "target_name": "dev", "node_id": "model.liga_sudoers_dbt.dim_pessoas"} */

    -- back compat for old kwarg name
  
  
  
      
          
          
      
  

  

  merge into silver.dim_pessoas as DBT_INTERNAL_DEST
      using dim_pessoas__dbt_tmp as DBT_INTERNAL_SOURCE
      on 
              DBT_INTERNAL_SOURCE.id = DBT_INTERNAL_DEST.id
          

      when matched then update set
         * 

      when not matched then insert *

[0m18:57:58.984006 [debug] [Thread-3 (]: SQL status: OK in 45.790 seconds
[0m18:57:59.068259 [debug] [Thread-3 (]: On model.liga_sudoers_dbt.dim_pessoas: ROLLBACK
[0m18:57:59.071798 [debug] [Thread-3 (]: Spark adapter: NotImplemented: rollback
[0m18:57:59.075508 [debug] [Thread-3 (]: On model.liga_sudoers_dbt.dim_pessoas: Close
[0m18:57:59.089874 [info ] [Thread-3 (]: 1 of 3 OK created sql incremental model silver.dim_pessoas ..................... [[32mOK[0m in 72.81s]
[0m18:57:59.094725 [debug] [Thread-3 (]: Finished running node model.liga_sudoers_dbt.dim_pessoas
[0m18:57:59.099668 [debug] [Thread-3 (]: Began running node model.liga_sudoers_dbt.dim_produtos
[0m18:57:59.102992 [info ] [Thread-3 (]: 2 of 3 START sql incremental model silver.dim_produtos ......................... [RUN]
[0m18:57:59.107465 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.liga_sudoers_dbt.dim_pessoas, now model.liga_sudoers_dbt.dim_produtos)
[0m18:57:59.109139 [debug] [Thread-3 (]: Began compiling node model.liga_sudoers_dbt.dim_produtos
[0m18:57:59.130426 [debug] [Thread-3 (]: Writing injected SQL for node "model.liga_sudoers_dbt.dim_produtos"
[0m18:57:59.136163 [debug] [Thread-3 (]: Began executing node model.liga_sudoers_dbt.dim_produtos
[0m18:57:59.148473 [debug] [Thread-3 (]: Spark adapter: NotImplemented: add_begin_query
[0m18:57:59.150177 [debug] [Thread-3 (]: Using spark connection "model.liga_sudoers_dbt.dim_produtos"
[0m18:57:59.152996 [debug] [Thread-3 (]: On model.liga_sudoers_dbt.dim_produtos: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "default", "target_name": "dev", "node_id": "model.liga_sudoers_dbt.dim_produtos"} */

  
    create or replace temporary view dim_produtos__dbt_tmp as
      

WITH cleaned_data AS (
    SELECT 
        p.id, 
        c.descricao AS cat_desc, 
        p.descricao, 
        p.created_at, 
        p.updated_at     
    FROM bronze.produtos p 
            INNER JOIN bronze.categorias c ON c.id = p.id_categoria
    
        -- Pega apenas registros que foram atualizados após o último update da tabela
        WHERE p.updated_at > (SELECT MAX(p.updated_at) FROM silver.dim_produtos)
    
)

SELECT * FROM cleaned_data;
  
[0m18:57:59.156922 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m18:58:02.521389 [debug] [Thread-3 (]: Spark adapter: Error while running:
/* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "default", "target_name": "dev", "node_id": "model.liga_sudoers_dbt.dim_produtos"} */

  
    create or replace temporary view dim_produtos__dbt_tmp as
      

WITH cleaned_data AS (
    SELECT 
        p.id, 
        c.descricao AS cat_desc, 
        p.descricao, 
        p.created_at, 
        p.updated_at     
    FROM bronze.produtos p 
            INNER JOIN bronze.categorias c ON c.id = p.id_categoria
    
        -- Pega apenas registros que foram atualizados após o último update da tabela
        WHERE p.updated_at > (SELECT MAX(p.updated_at) FROM silver.dim_produtos)
    
)

SELECT * FROM cleaned_data;
  
[0m18:58:02.526813 [debug] [Thread-3 (]: Spark adapter: Runtime Error
  [UNSUPPORTED_SUBQUERY_EXPRESSION_CATEGORY.CORRELATED_REFERENCE] Unsupported subquery expression: Expressions referencing the outer query are not supported outside of WHERE/HAVING clauses: "max(updated_at) AS `max(outer(p.updated_at))`".; line 18 pos 30
[0m18:58:02.547240 [debug] [Thread-3 (]: On model.liga_sudoers_dbt.dim_produtos: ROLLBACK
[0m18:58:02.549219 [debug] [Thread-3 (]: Spark adapter: NotImplemented: rollback
[0m18:58:02.550911 [debug] [Thread-3 (]: On model.liga_sudoers_dbt.dim_produtos: Close
[0m18:58:02.632235 [debug] [Thread-3 (]: Runtime Error in model dim_produtos (models/silver/dim_produtos.sql)
  Runtime Error
    [UNSUPPORTED_SUBQUERY_EXPRESSION_CATEGORY.CORRELATED_REFERENCE] Unsupported subquery expression: Expressions referencing the outer query are not supported outside of WHERE/HAVING clauses: "max(updated_at) AS `max(outer(p.updated_at))`".; line 18 pos 30
[0m18:58:02.639754 [error] [Thread-3 (]: 2 of 3 ERROR creating sql incremental model silver.dim_produtos ................ [[31mERROR[0m in 3.53s]
[0m18:58:02.643122 [debug] [Thread-3 (]: Finished running node model.liga_sudoers_dbt.dim_produtos
[0m18:58:02.644618 [debug] [Thread-3 (]: Began running node model.liga_sudoers_dbt.fato_pedidos
[0m18:58:02.659816 [debug] [Thread-6 (]: Marking all children of 'model.liga_sudoers_dbt.dim_produtos' to be skipped because of status 'error'.  Reason: Runtime Error in model dim_produtos (models/silver/dim_produtos.sql)
  Runtime Error
    [UNSUPPORTED_SUBQUERY_EXPRESSION_CATEGORY.CORRELATED_REFERENCE] Unsupported subquery expression: Expressions referencing the outer query are not supported outside of WHERE/HAVING clauses: "max(updated_at) AS `max(outer(p.updated_at))`".; line 18 pos 30.
[0m18:58:02.656741 [info ] [Thread-3 (]: 3 of 3 START sql incremental model silver.fato_pedidos ......................... [RUN]
[0m18:58:02.666601 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.liga_sudoers_dbt.dim_produtos, now model.liga_sudoers_dbt.fato_pedidos)
[0m18:58:02.667918 [debug] [Thread-3 (]: Began compiling node model.liga_sudoers_dbt.fato_pedidos
[0m18:58:02.702271 [debug] [Thread-3 (]: Writing injected SQL for node "model.liga_sudoers_dbt.fato_pedidos"
[0m18:58:02.710598 [debug] [Thread-3 (]: Began executing node model.liga_sudoers_dbt.fato_pedidos
[0m18:58:02.736033 [debug] [Thread-3 (]: Spark adapter: NotImplemented: add_begin_query
[0m18:58:02.739082 [debug] [Thread-3 (]: Using spark connection "model.liga_sudoers_dbt.fato_pedidos"
[0m18:58:02.743715 [debug] [Thread-3 (]: On model.liga_sudoers_dbt.fato_pedidos: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "default", "target_name": "dev", "node_id": "model.liga_sudoers_dbt.fato_pedidos"} */

  
    create or replace temporary view fato_pedidos__dbt_tmp as
      
WITH orders AS (
    SELECT 
        p.id AS id_pedido, 
        p.id_pessoa, 
        i.id_produto, 
        a.dispositivo, 
        a.geohash,
        a.telefone,
        p.dt_venda,
        i.qtde, 
        i.valor_total AS valor_unit,
        p.valor_total, 
        p.created_at,
        p.updated_at
    FROM bronze.pedidos p 
        INNER JOIN bronze.itens_pedidos i 
        ON p.id = i.id_pedido 
        INNER JOIN bronze.auditoria_pedidos a 
        ON p.id = a.id_pedido
    
        -- Pega apenas registros que foram atualizados após o último update da tabela
        WHERE p.updated_at > (SELECT MAX(p.updated_at) FROM silver.fato_pedidos)
    

)

SELECT * FROM orders;
  
[0m18:58:02.747896 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m18:58:07.918362 [debug] [Thread-3 (]: Spark adapter: Error while running:
/* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "default", "target_name": "dev", "node_id": "model.liga_sudoers_dbt.fato_pedidos"} */

  
    create or replace temporary view fato_pedidos__dbt_tmp as
      
WITH orders AS (
    SELECT 
        p.id AS id_pedido, 
        p.id_pessoa, 
        i.id_produto, 
        a.dispositivo, 
        a.geohash,
        a.telefone,
        p.dt_venda,
        i.qtde, 
        i.valor_total AS valor_unit,
        p.valor_total, 
        p.created_at,
        p.updated_at
    FROM bronze.pedidos p 
        INNER JOIN bronze.itens_pedidos i 
        ON p.id = i.id_pedido 
        INNER JOIN bronze.auditoria_pedidos a 
        ON p.id = a.id_pedido
    
        -- Pega apenas registros que foram atualizados após o último update da tabela
        WHERE p.updated_at > (SELECT MAX(p.updated_at) FROM silver.fato_pedidos)
    

)

SELECT * FROM orders;
  
[0m18:58:07.920202 [debug] [Thread-3 (]: Spark adapter: Runtime Error
  [UNSUPPORTED_SUBQUERY_EXPRESSION_CATEGORY.CORRELATED_REFERENCE] Unsupported subquery expression: Expressions referencing the outer query are not supported outside of WHERE/HAVING clauses: "max(updated_at) AS `max(outer(p.updated_at))`".; line 27 pos 30
[0m18:58:07.922616 [debug] [Thread-3 (]: On model.liga_sudoers_dbt.fato_pedidos: ROLLBACK
[0m18:58:07.925272 [debug] [Thread-3 (]: Spark adapter: NotImplemented: rollback
[0m18:58:07.928245 [debug] [Thread-3 (]: On model.liga_sudoers_dbt.fato_pedidos: Close
[0m18:58:07.961683 [debug] [Thread-3 (]: Runtime Error in model fato_pedidos (models/silver/fato_pedidos.sql)
  Runtime Error
    [UNSUPPORTED_SUBQUERY_EXPRESSION_CATEGORY.CORRELATED_REFERENCE] Unsupported subquery expression: Expressions referencing the outer query are not supported outside of WHERE/HAVING clauses: "max(updated_at) AS `max(outer(p.updated_at))`".; line 27 pos 30
[0m18:58:07.967540 [error] [Thread-3 (]: 3 of 3 ERROR creating sql incremental model silver.fato_pedidos ................ [[31mERROR[0m in 5.30s]
[0m18:58:07.975304 [debug] [Thread-3 (]: Finished running node model.liga_sudoers_dbt.fato_pedidos
[0m18:58:07.978007 [debug] [Thread-6 (]: Marking all children of 'model.liga_sudoers_dbt.fato_pedidos' to be skipped because of status 'error'.  Reason: Runtime Error in model fato_pedidos (models/silver/fato_pedidos.sql)
  Runtime Error
    [UNSUPPORTED_SUBQUERY_EXPRESSION_CATEGORY.CORRELATED_REFERENCE] Unsupported subquery expression: Expressions referencing the outer query are not supported outside of WHERE/HAVING clauses: "max(updated_at) AS `max(outer(p.updated_at))`".; line 27 pos 30.
[0m18:58:07.984793 [debug] [MainThread]: On master: ROLLBACK
[0m18:58:07.986323 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:58:07.987640 [debug] [MainThread]: Spark adapter: NotImplemented: rollback
[0m18:58:07.988906 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m18:58:07.991049 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m18:58:07.992920 [debug] [MainThread]: On master: ROLLBACK
[0m18:58:07.996123 [debug] [MainThread]: Spark adapter: NotImplemented: rollback
[0m18:58:07.999491 [debug] [MainThread]: On master: Close
[0m18:58:08.004205 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:58:08.007912 [debug] [MainThread]: Connection 'model.liga_sudoers_dbt.fato_pedidos' was properly closed.
[0m18:58:08.013754 [info ] [MainThread]: 
[0m18:58:08.020331 [info ] [MainThread]: Finished running 3 incremental models in 0 hours 2 minutes and 5.92 seconds (125.92s).
[0m18:58:08.041745 [debug] [MainThread]: Command end result
[0m18:58:08.346339 [debug] [MainThread]: Wrote artifact WritableManifest to /tmp/target/manifest.json
[0m18:58:08.370283 [debug] [MainThread]: Wrote artifact SemanticManifest to /tmp/target/semantic_manifest.json
[0m18:58:08.483828 [debug] [MainThread]: Wrote artifact RunExecutionResult to /tmp/target/run_results.json
[0m18:58:08.488132 [info ] [MainThread]: 
[0m18:58:08.499673 [info ] [MainThread]: [31mCompleted with 2 errors, 0 partial successes, and 0 warnings:[0m
[0m18:58:08.505662 [info ] [MainThread]: 
[0m18:58:08.517229 [error] [MainThread]:   Runtime Error in model dim_produtos (models/silver/dim_produtos.sql)
  Runtime Error
    [UNSUPPORTED_SUBQUERY_EXPRESSION_CATEGORY.CORRELATED_REFERENCE] Unsupported subquery expression: Expressions referencing the outer query are not supported outside of WHERE/HAVING clauses: "max(updated_at) AS `max(outer(p.updated_at))`".; line 18 pos 30
[0m18:58:08.519472 [info ] [MainThread]: 
[0m18:58:08.521229 [error] [MainThread]:   Runtime Error in model fato_pedidos (models/silver/fato_pedidos.sql)
  Runtime Error
    [UNSUPPORTED_SUBQUERY_EXPRESSION_CATEGORY.CORRELATED_REFERENCE] Unsupported subquery expression: Expressions referencing the outer query are not supported outside of WHERE/HAVING clauses: "max(updated_at) AS `max(outer(p.updated_at))`".; line 27 pos 30
[0m18:58:08.523839 [info ] [MainThread]: 
[0m18:58:08.525293 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=2 SKIP=0 TOTAL=3
[0m18:58:08.533165 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 136.80084, "process_in_blocks": "21216", "process_kernel_time": 1.663557, "process_mem_max_rss": "115956", "process_out_blocks": "3256", "process_user_time": 19.311995}
[0m18:58:08.538543 [debug] [MainThread]: Command `dbt run` failed at 18:58:08.536970 after 136.81 seconds
[0m18:58:08.542237 [debug] [MainThread]: Flushing usage events
